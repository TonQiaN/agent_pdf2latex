{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c7c277b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import google.genai as genai\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.messages import HumanMessage\n",
    "from pathlib import Path\n",
    "\n",
    "# Read the environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c03e737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è´ Ê≠£Âú®‰∏ä‰º† ../.example/paper.pdf ...\n",
      "‚úÖ ‰∏ä‰º†ÂÆåÊàê: paper_pdf_uri ‚Üí https://generativelanguage.googleapis.com/v1beta/files/o6isoica6d8h\n",
      "‚è´ Ê≠£Âú®‰∏ä‰º† ../.example/solution.pdf ...\n",
      "‚úÖ ‰∏ä‰º†ÂÆåÊàê: solution_pdf_uri ‚Üí https://generativelanguage.googleapis.com/v1beta/files/s1b7kk5wrk38\n"
     ]
    }
   ],
   "source": [
    "# Set path\n",
    "CACHE_FILE = \"./file_cache.json\"\n",
    "question_pdf_path = \"../.example/paper.pdf\"\n",
    "solution_pdf_path = \"../.example/solution.pdf\"\n",
    "\n",
    "def load_cache():\n",
    "    \"\"\"Read the cache in JSON format\"\"\"\n",
    "    if os.path.exists(CACHE_FILE):\n",
    "        with open(CACHE_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "    return {}\n",
    "\n",
    "def save_cache(cache: dict):\n",
    "    \"\"\"Save the cache in JSON format\"\"\"\n",
    "    with open(CACHE_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(cache, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "def upload_if_needed(path: str, cache_key: str):\n",
    "    \"\"\"\n",
    "    Get the file uri if it has already been uploaded.\n",
    "    If not, upload the file to google and return the uri.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the cache\n",
    "    cache = load_cache()\n",
    "\n",
    "    # If the file uri is already cached, return it.\n",
    "    if cache_key in cache:\n",
    "        print(f\"‚úÖ Â∑≤ÁºìÂ≠ò: {cache_key} ‚Üí {cache[cache_key]}\")\n",
    "        return cache[cache_key]\n",
    "\n",
    "    # If not, get the client and upload the file.\n",
    "    client = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "\n",
    "    print(f\"‚è´ Ê≠£Âú®‰∏ä‰º† {path} ...\")\n",
    "    uploaded = client.files.upload(file=path)\n",
    "    cache[cache_key] = uploaded.uri\n",
    "    save_cache(cache)\n",
    "    print(f\"‚úÖ ‰∏ä‰º†ÂÆåÊàê: {cache_key} ‚Üí {uploaded.uri}\")\n",
    "    return uploaded.uri\n",
    "\n",
    "def delete_all_files():\n",
    "    client = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "    files = client.files.list()\n",
    "\n",
    "    for f in files:\n",
    "        client.files.delete(name=f.name)\n",
    "        print(f\"üóëÔ∏è Â∑≤Âà†Èô§: {f.name}\")\n",
    "\n",
    "    # if os.path.exists(CACHE_FILE):\n",
    "    #     with open(CACHE_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    #         json.dump({}, f, indent=2, ensure_ascii=False)\n",
    "    #     print(f\"üßπ Â∑≤Ê∏ÖÁ©∫ÁºìÂ≠òÊñá‰ª∂: {CACHE_FILE}\")\n",
    "    # else:\n",
    "    #     print(\"‚ÑπÔ∏è Êú™ÊâæÂà∞ÁºìÂ≠òÊñá‰ª∂ÔºåÊó†ÈúÄÊ∏ÖÁ©∫„ÄÇ\")\n",
    "\n",
    "\n",
    "q_uri = upload_if_needed(question_pdf_path, \"paper_pdf_uri\")\n",
    "s_uri = upload_if_needed(solution_pdf_path, \"solution_pdf_uri\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36ea7ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    URI:   https://generativelanguage.googleapis.com/v1beta/files/s1b7kk5wrk38\n",
      "    NAME:  files/s1b7kk5wrk38\n",
      "    STATE: FileState.ACTIVE\n",
      "    SIZE:  9230.1 KB\n",
      "    TIME:  2025-11-11 14:13:15.100045+00:00\n",
      "    \n",
      "\n",
      "    URI:   https://generativelanguage.googleapis.com/v1beta/files/o6isoica6d8h\n",
      "    NAME:  files/o6isoica6d8h\n",
      "    STATE: FileState.ACTIVE\n",
      "    SIZE:  518.9 KB\n",
      "    TIME:  2025-11-11 14:12:20.298004+00:00\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "def list_all_uploaded_files():\n",
    "    client = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "    files = client.files.list()\n",
    "\n",
    "    for f in files:\n",
    "        print(f\"\"\"\n",
    "    URI:   {f.uri}\n",
    "    NAME:  {f.name}\n",
    "    STATE: {f.state}\n",
    "    SIZE:  {f.size_bytes / 1024:.1f} KB\n",
    "    TIME:  {f.create_time}\n",
    "    \"\"\")\n",
    "\n",
    "list_all_uploaded_files()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0460b670",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[],\n",
    "    system_prompt=\"You are an Australian high school teacher.\",\n",
    ")\n",
    "\n",
    "# === 3. ÊûÑÈÄ†Ê∂àÊÅØÂπ∂ÊâßË°å ===\n",
    "question = HumanMessage(content=[\n",
    "    {\"type\": \"text\", \"text\":\n",
    "        \"You are an Australian high school teacher.\\n\"\n",
    "        \"Please ONLY summarize the content of the third page of the solution PDF. Do NOT scan the whole PDF. \"\n",
    "    },\n",
    "    {\"type\": \"media\", \"mime_type\": \"application/pdf\", \"file_uri\": q_uri},\n",
    "    {\"type\": \"media\", \"mime_type\": \"application/pdf\", \"file_uri\": s_uri},\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d2b379",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in agent.stream({\"messages\": [question]}, stream_mode=\"values\"):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
