"""Exam Type Classifier Agent"""

import json
import time
from typing import Tuple, TYPE_CHECKING
from loguru import logger
from agents import Usage

if TYPE_CHECKING:
    from . import UsageWithDuration

from ..config.settings import settings
from ..models.schemas import ExamTypeOutput
from ..clients.client_manager import ClientManager
from ..clients.base import LLMMessage, MessageContent, MessageRole, ContentType


def get_classifier_prompt() -> str:
    """
    åˆ†ç±»å™¨æç¤ºè¯ï¼ˆä¸ import_v3 ä¸€è‡´ï¼‰
    """
    return """Analyze the provided pages of this exam and determine its type.

**Type1** (Separate Answer Booklet):
- Explicitly states "Use a SEPARATE writing booklet" or similar
- No blank lines or answer spaces under questions
- Questions are densely packed
- Example: "10(a)", "10(b)", "10(c)" are independent questions

**Type2** (Answer on Paper):
- Has blank lines or answer spaces under questions, including:
  * Underscores (______)
  * Dotted lines (..................)
  * Multiple blank lines for writing answers
- Clear answer spaces between questions
- Questions have more spacing
- Example: "Question 21" is one complete question with sub-parts (a), (b), (c)

**Analysis Guidelines**:
1. Look for explicit instructions about where to write answers
2. Check for blank answer spaces or lines
3. Observe question density and spacing
4. Note the question numbering pattern

Return JSON with:
{
    "exam_type": "type1" or "type2",
    "reasoning": "Detailed explanation of classification decision",
    "confidence": 0.0-1.0 (optional)
}

**Important**: Base your decision on multiple indicators, not just one feature.
"""


async def classify_exam_type_direct(classification_data: dict) -> Tuple[str, "UsageWithDuration"]:
    """
    ä½¿ç”¨ clients ç›´æ¥è°ƒç”¨ API è¿›è¡Œè¯•å·ç±»å‹åˆ†ç±»ï¼ˆä¸ä½¿ç”¨ agents æ¡†æ¶ï¼‰
    
    è¿™æ˜¯ä¸€ä¸ªæ›¿ä»£å®ç°ï¼Œç”¨äºå¯¹æ¯”æµ‹è¯•ï¼š
    - ç›´æ¥ä½¿ç”¨ OpenAIClient è°ƒç”¨ Vision API
    - æ‰‹åŠ¨æ„é€ æ¶ˆæ¯å’Œè§£æå“åº”
    - æ‰‹åŠ¨æ„é€  Usage å¯¹è±¡
    
    Args:
        classification_data: é¢„å¤„ç†æ•°æ®ï¼ŒåŒ…å« selected_pages
    
    Returns:
        Tuple[str, UsageWithDuration]: (è¯•å·ç±»å‹, APIä½¿ç”¨ç»Ÿè®¡å«æ—¶é—´)
    """
    from . import UsageWithDuration
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    
    # åˆ›å»ºå®¢æˆ·ç«¯
    client = ClientManager.create_classifier_client()
    
    selected_pages = classification_data["selected_pages"]
    page_numbers = [p["page_number"] for p in selected_pages]
    
    logger.info(f"ğŸ“Š Classifying exam type using pages (Direct API): {page_numbers}")
    
    # æ„å»ºç³»ç»Ÿæç¤º
    system_prompt = get_classifier_prompt()
    
    # æ„å»ºç”¨æˆ·æ¶ˆæ¯ï¼ˆåŒ…å«3å¼ å›¾ç‰‡ï¼‰
    user_content = [
        MessageContent(
            type=ContentType.TEXT,
            text="Analyze these pages to determine exam type:"
        )
    ]
    
    # æ·»åŠ æ¯ä¸ªé¡µé¢çš„å›¾ç‰‡
    for page in selected_pages:
        user_content.append(
            MessageContent(
                type=ContentType.TEXT,
                text=f"\n\nPage {page['page_number']}:"
            )
        )
        user_content.append(
            MessageContent(
                type=ContentType.IMAGE,
                image_base64=page['image_base64']
            )
        )
    
    # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
    messages = [
        LLMMessage(
            role=MessageRole.SYSTEM,
            content=system_prompt
        ),
        LLMMessage(
            role=MessageRole.USER,
            content=user_content
        )
    ]
    
    # è°ƒç”¨ APIï¼ˆä½¿ç”¨ JSON æ¨¡å¼ï¼‰
    try:
        response = await client.aquery(
            messages=messages,
            temperature=0.0,
            max_tokens=2000,  # å¢åŠ é™åˆ¶ä»¥ç¡®ä¿å®Œæ•´å“åº”ï¼ˆåˆ†ç±»ä»»åŠ¡ç®€å•ï¼Œ2000è¶³å¤Ÿï¼‰
            response_format={"type": "json_object"}  # JSON æ¨¡å¼
        )
        
        # æ£€æŸ¥å“åº”å†…å®¹
        if not response.content:
            logger.error("Empty response content from API")
            logger.error(f"Response object: {response}")
            logger.error(f"Response finish_reason: {response.finish_reason}")
            logger.error(f"Response usage: {response.usage}")
            
            # å¦‚æœæ˜¯å› ä¸ºé•¿åº¦é™åˆ¶ï¼Œæä¾›æ›´æœ‰ç”¨çš„é”™è¯¯ä¿¡æ¯
            if response.finish_reason == 'length':
                raise ValueError(
                    f"API response was truncated due to max_tokens limit. "
                    f"Tokens used: {response.usage.get('completion_tokens', 0)}. "
                    f"Consider increasing max_tokens parameter."
                )
            else:
                raise ValueError("API returned empty content. This may be due to a refusal or error.")
        
        # è§£æ JSON å“åº”
        response_data = json.loads(response.content)
        
        # æå–åˆ†ç±»ç»“æœ
        exam_type = response_data.get("exam_type", "type1")
        reasoning = response_data.get("reasoning", "")
        confidence = response_data.get("confidence")
        
        # æ‰‹åŠ¨æ„é€  Usage å¯¹è±¡
        usage = Usage()
        if response.usage:
            usage.requests = 1
            usage.input_tokens = response.usage.get("prompt_tokens", 0)
            usage.output_tokens = response.usage.get("completion_tokens", 0)
            usage.total_tokens = response.usage.get("total_tokens", 0)
        
        # è®¡ç®—è€—æ—¶
        duration = time.time() - start_time
        
        # è¾“å‡ºæ—¥å¿—
        logger.info(f"âœ“ Classification result (Direct API): {exam_type}")
        logger.info(f"   Reasoning: {reasoning}")
        if confidence:
            logger.info(f"   Confidence: {confidence:.2f}")
        logger.info(f"   Duration: {duration:.2f}s")
        logger.info(f"   API Usage: {usage.input_tokens} input + {usage.output_tokens} output = {usage.total_tokens} tokens")
        
        # è¿”å›å¸¦æ—¶é—´çš„ usage
        usage_with_duration = UsageWithDuration(usage=usage, duration_seconds=duration)
        return exam_type, usage_with_duration
        
    except json.JSONDecodeError as e:
        logger.error(f"Failed to parse JSON response: {e}")
        logger.error(f"Response content: {response.content if response.content else '(empty)'}")
        logger.error(f"Response finish_reason: {response.finish_reason if hasattr(response, 'finish_reason') else 'N/A'}")
        logger.error(f"Full response: {response}")
        raise
    except ValueError as e:
        logger.error(f"Invalid response: {e}")
        raise
    except Exception as e:
        logger.error(f"Classification failed: {e}")
        raise

