{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c7c277b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.messages import HumanMessage\n",
    "from pathlib import Path\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Literal\n",
    "\n",
    "# Read the environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client\n",
    "openai_client = AsyncOpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c03e737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÁºìÂ≠ò: paper_pdf_id ‚Üí file-1MVpD6pbVE2henLJ4uiPvf\n",
      "‚úÖ Â∑≤ÁºìÂ≠ò: solution_pdf_id ‚Üí file-ChAcwXYkWKiuYT54Pdm4LQ\n",
      "\n",
      "üìÑ Paper File ID: file-1MVpD6pbVE2henLJ4uiPvf\n",
      "üìÑ Solution File ID: file-ChAcwXYkWKiuYT54Pdm4LQ\n"
     ]
    }
   ],
   "source": [
    "# Set path\n",
    "CACHE_FILE = \"./file_cache_openai.json\"\n",
    "paper_pdf_path = \"../.example/paper.pdf\"\n",
    "solution_pdf_path = \"../.example/solution.pdf\"\n",
    "\n",
    "def load_cache():\n",
    "    \"\"\"Read the cache in JSON format\"\"\"\n",
    "    if os.path.exists(CACHE_FILE):\n",
    "        with open(CACHE_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "    return {}\n",
    "\n",
    "def save_cache(cache: dict):\n",
    "    \"\"\"Save the cache in JSON format\"\"\"\n",
    "    with open(CACHE_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(cache, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "async def upload_if_needed(path: str, cache_key: str):\n",
    "    \"\"\"\n",
    "    Get the file ID if it has already been uploaded.\n",
    "    If not, upload the file to OpenAI and return the file ID.\n",
    "    \n",
    "    Note: OpenAI uses file IDs, not URIs\n",
    "    \"\"\"\n",
    "    # Load the cache\n",
    "    cache = load_cache()\n",
    "\n",
    "    # If the file ID is already cached, return it.\n",
    "    if cache_key in cache:\n",
    "        file_id = cache[cache_key]\n",
    "        print(f\"‚úÖ Â∑≤ÁºìÂ≠ò: {cache_key} ‚Üí {file_id}\")\n",
    "        \n",
    "        # Verify file still exists\n",
    "        try:\n",
    "            await openai_client.files.retrieve(file_id)\n",
    "            return file_id\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è ÁºìÂ≠òÁöÑÊñá‰ª∂Â∑≤Â§±ÊïàÔºåÈáçÊñ∞‰∏ä‰º†...\")\n",
    "            cache.pop(cache_key, None)\n",
    "\n",
    "    # Upload file to OpenAI\n",
    "    print(f\"‚è´ Ê≠£Âú®‰∏ä‰º†Âà∞ OpenAI: {path} ...\")\n",
    "    with open(path, 'rb') as f:\n",
    "        uploaded = await openai_client.files.create(\n",
    "            file=f,\n",
    "            purpose=\"assistants\"  # OpenAI ÈúÄË¶ÅÊåáÂÆöÁî®ÈÄî\n",
    "        )\n",
    "    \n",
    "    file_id = uploaded.id\n",
    "    cache[cache_key] = file_id\n",
    "    save_cache(cache)\n",
    "    print(f\"‚úÖ ‰∏ä‰º†ÂÆåÊàê: {cache_key} ‚Üí {file_id}\")\n",
    "    return file_id\n",
    "\n",
    "async def list_all_uploaded_files():\n",
    "    \"\"\"ÂàóÂá∫ÊâÄÊúâÂ∑≤‰∏ä‰º†ÁöÑÊñá‰ª∂\"\"\"\n",
    "    files = await openai_client.files.list()\n",
    "    \n",
    "    print(\"\\nüìÅ OpenAI Â∑≤‰∏ä‰º†Êñá‰ª∂ÂàóË°®:\")\n",
    "    for f in files.data:\n",
    "        print(f\"\"\"\n",
    "    ID:       {f.id}\n",
    "    Filename: {f.filename}\n",
    "    Purpose:  {f.purpose}\n",
    "    Size:     {f.bytes / 1024:.1f} KB\n",
    "    Created:  {f.created_at}\n",
    "        \"\"\")\n",
    "\n",
    "async def delete_all_files():\n",
    "    \"\"\"Âà†Èô§ÊâÄÊúâÂ∑≤‰∏ä‰º†ÁöÑÊñá‰ª∂\"\"\"\n",
    "    files = await openai_client.files.list()\n",
    "    \n",
    "    for f in files.data:\n",
    "        await openai_client.files.delete(f.id)\n",
    "        print(f\"üóëÔ∏è Â∑≤Âà†Èô§: {f.id} ({f.filename})\")\n",
    "    \n",
    "    print(f\"‚úÖ Â∑≤Âà†Èô§ {len(files.data)} ‰∏™Êñá‰ª∂\")\n",
    "\n",
    "\n",
    "# ‰∏ä‰º† PDF Êñá‰ª∂\n",
    "paper_file_id = await upload_if_needed(paper_pdf_path, \"paper_pdf_id\")\n",
    "solution_file_id = await upload_if_needed(solution_pdf_path, \"solution_pdf_id\")\n",
    "\n",
    "print(f\"\\nüìÑ Paper File ID: {paper_file_id}\")\n",
    "print(f\"üìÑ Solution File ID: {solution_file_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36ea7ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ OpenAI Â∑≤‰∏ä‰º†Êñá‰ª∂ÂàóË°®:\n",
      "\n",
      "    ID:       file-ChAcwXYkWKiuYT54Pdm4LQ\n",
      "    Filename: solution.pdf\n",
      "    Purpose:  assistants\n",
      "    Size:     9230.1 KB\n",
      "    Created:  1762882475\n",
      "        \n",
      "\n",
      "    ID:       file-1MVpD6pbVE2henLJ4uiPvf\n",
      "    Filename: paper.pdf\n",
      "    Purpose:  assistants\n",
      "    Size:     518.9 KB\n",
      "    Created:  1762882457\n",
      "        \n",
      "\n",
      "    ID:       file-4VtAqpn7qJfL6QZHKTs4jp\n",
      "    Filename: first5_solution.pdf\n",
      "    Purpose:  assistants\n",
      "    Size:     835.5 KB\n",
      "    Created:  1762433905\n",
      "        \n",
      "\n",
      "    ID:       file-4HKYQitwgmU74U1Q1puaVN\n",
      "    Filename: solution.pdf\n",
      "    Purpose:  assistants\n",
      "    Size:     9230.1 KB\n",
      "    Created:  1762430651\n",
      "        \n",
      "\n",
      "    ID:       file-F4sS11gdBtzsCJKY4UHknK\n",
      "    Filename: paper.pdf\n",
      "    Purpose:  assistants\n",
      "    Size:     518.9 KB\n",
      "    Created:  1762430617\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# ÂàóÂá∫ÊâÄÊúâÂ∑≤‰∏ä‰º†ÁöÑÊñá‰ª∂\n",
    "await list_all_uploaded_files()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee75388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # System_head = \"\"\"\n",
    "# # You are an Australian high school teacher.\n",
    "# # You are asked to perform tasks related to the processing and analysis of exam papers to assist with student learning.\n",
    "# # \"\"\"\n",
    "\n",
    "# @dataclass\n",
    "# class FlowContext:\n",
    "#     \"\"\"\n",
    "#     Customized data class for flow\n",
    "#     \"\"\"\n",
    "#     step: Literal[\"classifier\", \"question_lister\"]\n",
    "#     exam_id: str\n",
    "#     exam_type: Optional[Literal[\"type1\", \"type2\"]] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e019463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PromptRegistry:\n",
    "#     def __init__(self):\n",
    "#         \"\"\"\n",
    "#         Manage all prompts for the flow.\n",
    "#         self._sections: Dict[str, List[str]] is a dictionary that stores the prompt sections for different steps.\n",
    "#         \"\"\"\n",
    "#         self._sections: Dict[str, List[str]] = {}\n",
    "    \n",
    "#     def register(self, step: str, *sections: str) -> None:\n",
    "#         \"\"\"Register a step's prompt sections\"\"\"\n",
    "#         self.sections.setdefault(step, []).extend([s.strip() for s in sections if s])\n",
    "    \n",
    "#     def build(self, step: str, **vars) -> str:\n",
    "#         \"\"\"Build the full prompt for a step, supporting variable interpolation\"\"\"\n",
    "#         parts = self.sections.get(step, [])\n",
    "#         if not parts:\n",
    "#             raise ValueError(f\"No prompt registered for step: {step}\")\n",
    "        \n",
    "#         # Simple variable interpolation (support str.format)\n",
    "#         blob = \"\\n\\n\".join(\n",
    "#             s.format(**vars) if \"{\" in s else s\n",
    "#             for s in parts\n",
    "#         )\n",
    "#         return blob\n",
    "\n",
    "#     def _register_classifier(self) -> None:\n",
    "#         \"\"\"Register the classifier prompt sections\"\"\"\n",
    "#         self.register(\n",
    "#             \"classify\",\n",
    "#             \"\"\"Analyze the provided pages of this exam and determine its type.\"\"\",\n",
    "            \n",
    "#             \"\"\"**Type1** (Separate Answer Booklet):\n",
    "#                 - Explicitly states \"Use a SEPARATE writing booklet\" or similar\n",
    "#                 - No blank lines or answer spaces under questions\n",
    "#                 - Questions are densely packed\n",
    "#                 - Example: \"10(a)\", \"10(b)\", \"10(c)\" are independent questions\"\"\",\n",
    "            \n",
    "#             \"\"\"**Type2** (Answer on Paper):\n",
    "#                 - Has blank lines or answer spaces under questions, including:\n",
    "#                 * Underscores (______)\n",
    "#                 * Dotted lines (..................)\n",
    "#                 * Multiple blank lines for writing answers\n",
    "#                 - Clear answer spaces between questions\n",
    "#                 - Questions have more spacing\n",
    "#                 - Example: \"Question 21\" is one complete question with sub-parts (a), (b), (c)\"\"\",\n",
    "                            \n",
    "#             \"\"\"**Analysis Guidelines**:\n",
    "#                 1. Look for explicit instructions about where to write answers\n",
    "#                 2. Check for blank answer spaces or lines\n",
    "#                 3. Observe question density and spacing\n",
    "#                 4. Note the question numbering pattern\"\"\",\n",
    "                            \n",
    "#             \"\"\"Return JSON with:\n",
    "#                 {{\n",
    "#                     \"exam_type\": \"type1\" or \"type2\",\n",
    "#                     \"reasoning\": \"Detailed explanation of classification decision\",\n",
    "#                     \"confidence\": 0.0-1.0 (optional)\n",
    "#                 }}\"\"\",\n",
    "\n",
    "#             \"\"\"**Important**: Base your decision on multiple indicators, not just one feature.\"\"\"\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07f067c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Optional, Literal\n",
    "from pathlib import Path\n",
    "\n",
    "# ============= ‰∏öÂä°‰∏ä‰∏ãÊñáÔºà‰º†ÈÄíÁªô runtime.contextÔºâ =============\n",
    "\n",
    "@dataclass\n",
    "class FlowContext:\n",
    "    \"\"\"\n",
    "    V4 File-Based Workflow ÁöÑËøêË°åÊó∂‰∏ä‰∏ãÊñá\n",
    "    Áî®‰∫éÂú®‰∏çÂêå Agent Ê≠•È™§Èó¥‰º†ÈÄíÁä∂ÊÄÅÂíåÈÖçÁΩÆ‰ø°ÊÅØ\n",
    "    \"\"\"\n",
    "    \n",
    "    # ========== Ê≠•È™§ÊéßÂà∂ ==========\n",
    "    step: Literal[\n",
    "        \"classify\",           # Step 0: ÂàÜÁ±ªËØïÂç∑Á±ªÂûã\n",
    "        \"lister\",             # Step 1: ÂàóÂá∫ÊâÄÊúâÈ¢òÁõÆ\n",
    "        \"annotate_paper\",     # Step 1.5: Ê†áÊ≥®È¢òÁõÆÂú® paper ‰∏≠ÁöÑÈ°µÁ†Å\n",
    "        \"annotate_solution\",  # Step 1.5: Ê†áÊ≥®È¢òÁõÆÂú® solution ‰∏≠ÁöÑÈ°µÁ†Å\n",
    "        \"question_latex\",     # Step 2: ÁîüÊàêÈ¢òÁõÆ LaTeX\n",
    "        \"answer_latex\",       # Step 3: ÁîüÊàêÁ≠îÊ°à LaTeX\n",
    "        \"bbox_correction\",    # Step 4: ÂõæÁâá bbox ‰øÆÊ≠£\n",
    "        \"labelling\"           # Step 5: È¢òÁõÆÊ†áÊ≥®Ôºàtopic/subtopic/type/difficultyÔºâ\n",
    "    ]\n",
    "    \n",
    "    # ========== ËØïÂç∑ÂÖÉÊï∞ÊçÆ ==========\n",
    "    exam_id: str                              # ËØïÂç∑ÂîØ‰∏ÄÊ†áËØÜ\n",
    "    exam_type: Optional[Literal[\"type1\", \"type2\"]] = None  # ËØïÂç∑Á±ªÂûãÔºàclassify ÂêéÂ°´ÂÖÖÔºâ\n",
    "    \n",
    "    # ========== Êñá‰ª∂Ë∑ØÂæÑ ==========\n",
    "    paper_pdf_path: Optional[str] = None      # ÂéüÂßã paper PDF Ë∑ØÂæÑ\n",
    "    solution_pdf_path: Optional[str] = None   # ÂéüÂßã solution PDF Ë∑ØÂæÑ\n",
    "    paper_file_id: Optional[str] = None       # OpenAI ‰∏ä‰º†ÁöÑ paper Êñá‰ª∂ ID\n",
    "    solution_file_id: Optional[str] = None    # OpenAI ‰∏ä‰º†ÁöÑ solution Êñá‰ª∂ ID\n",
    "    output_dir: Optional[Path] = None         # ËæìÂá∫ÁõÆÂΩï\n",
    "    \n",
    "    # ========== È¢òÁõÆ‰ø°ÊÅØÔºàlister ÂêéÂ°´ÂÖÖÔºâ ==========\n",
    "    total_questions: int = 0                  # È¢òÁõÆÊÄªÊï∞\n",
    "    current_question_index: Optional[int] = None    # ÂΩìÂâçÂ§ÑÁêÜÁöÑÈ¢òÁõÆÁ¥¢ÂºïÔºà1-basedÔºâ\n",
    "    current_question_label: Optional[str] = None    # ÂΩìÂâçÂ§ÑÁêÜÁöÑÈ¢òÁõÆÊ†áÁ≠æÔºàÂ¶Ç \"10(a)\"Ôºâ\n",
    "    paper_pages: Optional[List[int]] = None         # ÂΩìÂâçÈ¢òÁõÆÂú® paper ‰∏≠ÁöÑÈ°µÁ†ÅÔºà0-basedÔºâ\n",
    "    solution_pages: Optional[List[int]] = None      # ÂΩìÂâçÈ¢òÁõÆÂú® solution ‰∏≠ÁöÑÈ°µÁ†ÅÔºà0-basedÔºâ\n",
    "    \n",
    "    # ========== Ê†áÊ≥®Áõ∏ÂÖ≥Ôºàlabelling Èò∂ÊÆµ‰ΩøÁî®Ôºâ ==========\n",
    "    subject_id: Optional[int] = None          # Subject IDÔºàÁî®‰∫éËé∑Âèñ subtopicsÔºâ\n",
    "    grade_id: Optional[int] = None            # Grade IDÔºàÁî®‰∫éËé∑Âèñ subtopicsÔºâ\n",
    "    existing_mark: Optional[int] = None       # Â∑≤ÊèêÂèñÁöÑÂàÜÊï∞Ôºà‰º†ÈÄíÁªô labellingÔºâ\n",
    "    \n",
    "    # ========== ‰∏≠Èó¥‰ª∂ÊéßÂà∂ÂèÇÊï∞ ==========\n",
    "    token_budget: int = 16000                 # ‰∏≠Èó¥‰ª∂Áî®‰∫éË£ÅÂâ™Èïø prompt ÁöÑ‰∏äÈôê\n",
    "    max_tokens: int = 8000                    # API ËØ∑Ê±ÇÁöÑ max_tokens ÈôêÂà∂\n",
    "    temperature: float = 0.0                  # ÁîüÊàêÊ∏©Â∫¶\n",
    "    enable_retry: bool = True                 # ÊòØÂê¶ÂêØÁî®ÈáçËØïÊú∫Âà∂\n",
    "    retry_count: int = 0                      # ÂΩìÂâçÈáçËØïÊ¨°Êï∞\n",
    "    max_retries: int = 2                      # ÊúÄÂ§ßÈáçËØïÊ¨°Êï∞\n",
    "    \n",
    "    # ========== Â∑•ÂÖ∑ÊéßÂà∂ ==========\n",
    "    plan: Literal[\"basic\", \"pro\", \"premium\"] = \"pro\"  # Áî®‰∫éË£ÅÂâ™Â∑•ÂÖ∑ÁöÑËÆ°ÂàíÁ≠âÁ∫ß\n",
    "    available_tools: List[str] = field(default_factory=list)  # ÂΩìÂâçÊ≠•È™§ÂèØÁî®ÁöÑÂ∑•ÂÖ∑ÂàóË°®\n",
    "    \n",
    "    # ========== ÂõæÁâáÂ§ÑÁêÜÁõ∏ÂÖ≥ ==========\n",
    "    enable_bbox_correction: bool = True       # ÊòØÂê¶ÂêØÁî® bbox ‰øÆÊ≠£\n",
    "    bbox_correction_max_iterations: int = 4   # Bbox ‰øÆÊ≠£ÊúÄÂ§ßËø≠‰ª£Ê¨°Êï∞\n",
    "    render_quality: Literal[\"low\", \"medium\", \"high\"] = \"medium\"  # PDF Ê∏≤ÊüìË¥®Èáè\n",
    "    \n",
    "    # ========== ËæìÂá∫Ê†ºÂºèÊéßÂà∂ ==========\n",
    "    response_format: Literal[\"json_object\", \"text\"] = \"json_object\"  # API ÂìçÂ∫îÊ†ºÂºè\n",
    "    enable_output_validation: bool = True     # ÊòØÂê¶ÂêØÁî®ËæìÂá∫Ê†°È™å\n",
    "    \n",
    "    # ========== ÊÄßËÉΩ‰ºòÂåñ ==========\n",
    "    enable_concurrent: bool = True            # ÊòØÂê¶ÂêØÁî®Âπ∂ÂèëÂ§ÑÁêÜ\n",
    "    concurrent_batch_size: int = 5            # Âπ∂ÂèëÊâπÊ¨°Â§ßÂ∞è\n",
    "    \n",
    "    # ========== Ë∞ÉËØïÂíåÊó•Âøó ==========\n",
    "    debug_mode: bool = False                  # Ë∞ÉËØïÊ®°Âºè\n",
    "    save_intermediate_results: bool = True    # ÊòØÂê¶‰øùÂ≠ò‰∏≠Èó¥ÁªìÊûú\n",
    "    log_level: Literal[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"] = \"INFO\"\n",
    "    \n",
    "    # ========== ÁâπÂÆöÊ≠•È™§ÁöÑÈ¢ùÂ§ñÈÖçÁΩÆ ==========\n",
    "    extra_config: Dict = field(default_factory=dict)  # Â≠òÂÇ®Ê≠•È™§ÁâπÂÆöÁöÑÈ¢ùÂ§ñÈÖçÁΩÆ\n",
    "    \n",
    "    # ========== ËæÖÂä©ÊñπÊ≥ï ==========\n",
    "    \n",
    "    def is_type1(self) -> bool:\n",
    "        \"\"\"Âà§Êñ≠ÊòØÂê¶‰∏∫ type1 ËØïÂç∑\"\"\"\n",
    "        return self.exam_type == \"type1\"\n",
    "    \n",
    "    def is_type2(self) -> bool:\n",
    "        \"\"\"Âà§Êñ≠ÊòØÂê¶‰∏∫ type2 ËØïÂç∑\"\"\"\n",
    "        return self.exam_type == \"type2\"\n",
    "    \n",
    "    def get_question_context(self) -> str:\n",
    "        \"\"\"Ëé∑ÂèñÂΩìÂâçÈ¢òÁõÆÁöÑ‰∏ä‰∏ãÊñáÊèèËø∞\"\"\"\n",
    "        if self.current_question_label:\n",
    "            return f\"Question {self.current_question_label} (index: {self.current_question_index})\"\n",
    "        return \"No question context\"\n",
    "    \n",
    "    def get_step_config(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Ê†πÊçÆÂΩìÂâçÊ≠•È™§ËøîÂõûÂØπÂ∫îÁöÑÈÖçÁΩÆ\n",
    "        ÂèØÁî®‰∫é‰∏≠Èó¥‰ª∂Âä®ÊÄÅË∞ÉÊï¥ÂèÇÊï∞\n",
    "        \"\"\"\n",
    "        config = {\n",
    "            \"step\": self.step,\n",
    "            \"token_budget\": self.token_budget,\n",
    "            \"max_tokens\": self.max_tokens,\n",
    "            \"temperature\": self.temperature,\n",
    "            \"response_format\": self.response_format,\n",
    "        }\n",
    "        \n",
    "        # Ê≠•È™§ÁâπÂÆöÈÖçÁΩÆ\n",
    "        if self.step == \"classify\":\n",
    "            config.update({\n",
    "                \"max_tokens\": 2000,\n",
    "                \"enable_tools\": False,  # ÂàÜÁ±ª‰∏çÈúÄË¶ÅÂ∑•ÂÖ∑\n",
    "            })\n",
    "        elif self.step == \"lister\":\n",
    "            config.update({\n",
    "                \"max_tokens\": 16000,  # Question list ÂèØËÉΩËæÉÈïø\n",
    "                \"enable_tools\": True,\n",
    "                \"available_tools\": [\"file_search\"],\n",
    "                \"retry_on_validation_failure\": True,\n",
    "            })\n",
    "        elif self.step in [\"question_latex\", \"answer_latex\"]:\n",
    "            config.update({\n",
    "                \"max_tokens\": 8000,\n",
    "                \"enable_tools\": False,\n",
    "                \"enable_image_extraction\": True,\n",
    "            })\n",
    "        elif self.step == \"bbox_correction\":\n",
    "            config.update({\n",
    "                \"max_tokens\": 1000,\n",
    "                \"model\": \"gpt-5\",  # ‰ΩøÁî®Êõ¥Âº∫ÁöÑÊ®°Âûã\n",
    "                \"temperature\": 0.0,\n",
    "            })\n",
    "        elif self.step == \"labelling\":\n",
    "            config.update({\n",
    "                \"max_tokens\": 3000,\n",
    "                \"enable_tools\": False,\n",
    "                \"require_subtopic_list\": True,\n",
    "            })\n",
    "        \n",
    "        # ÂêàÂπ∂ extra_config\n",
    "        if self.extra_config:\n",
    "            config.update(self.extra_config)\n",
    "        \n",
    "        return config\n",
    "    \n",
    "    def clone_for_step(\n",
    "        self, \n",
    "        step: str, \n",
    "        question_index: Optional[int] = None,\n",
    "        question_label: Optional[str] = None,\n",
    "        **kwargs\n",
    "    ) -> \"FlowContext\":\n",
    "        \"\"\"\n",
    "        ÂÖãÈöÜ‰∏ä‰∏ãÊñáÂπ∂Êõ¥Êñ∞‰∏∫Êñ∞Ê≠•È™§\n",
    "        Áî®‰∫éÂú® workflow ‰∏≠ÂàáÊç¢Ê≠•È™§Êó∂‰øùÊåÅÁä∂ÊÄÅ\n",
    "        \"\"\"\n",
    "        from copy import deepcopy\n",
    "        new_context = deepcopy(self)\n",
    "        new_context.step = step\n",
    "        \n",
    "        if question_index is not None:\n",
    "            new_context.current_question_index = question_index\n",
    "        if question_label is not None:\n",
    "            new_context.current_question_label = question_label\n",
    "        \n",
    "        # Êõ¥Êñ∞ÂÖ∂‰ªñ‰º†ÂÖ•ÁöÑÂèÇÊï∞\n",
    "        for key, value in kwargs.items():\n",
    "            if hasattr(new_context, key):\n",
    "                setattr(new_context, key, value)\n",
    "        \n",
    "        return new_context\n",
    "    \n",
    "    def to_dict(self) -> Dict:\n",
    "        \"\"\"ËΩ¨Êç¢‰∏∫Â≠óÂÖ∏ÔºàÁî®‰∫éÊó•ÂøóÊàñÂ∫èÂàóÂåñÔºâ\"\"\"\n",
    "        from dataclasses import asdict\n",
    "        return asdict(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c12999e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CLASSIFIER PROMPT ===\n",
      "Analyze the provided pages of this exam and determine its type.\n",
      "\n",
      "**Type1** (Separate Answer Booklet):\n",
      "- Explicitly states \"Use a SEPARATE writing booklet\" or similar\n",
      "- No blank lines or answer spaces under questions\n",
      "- Questions are densely packed\n",
      "- Example: \"10(a)\", \"10(b)\", \"10(c)\" are independent questions\n",
      "\n",
      "**Type2** (Answer on Paper):\n",
      "- Has blank lines or answer spaces under questions, including:\n",
      "  * Underscores (______)\n",
      "  * Dotted lines (..................)\n",
      "  * Multiple blank lines for writi\n",
      "\n",
      "\n",
      "=== LISTER PROMPT (Type1) ===\n",
      "You are a Question Lister Agent. Your task is to scan the entire paper PDF and create a **complete, accurate list** of all questions.\n",
      "\n",
      "=== Exam Type ===\n",
      "type1\n",
      "\n",
      "=== Question Splitting Rules ===\n",
      "„ÄêType1 Rules„Äë(Separate Answer Booklet):\n",
      "- Question 10 is a **section title**, not an independent question\n",
      "- 10(a), 10(b), 10(c) are **independent questions** (minimum splitting unit)\n",
      "- 10(c)(i), 10(c)(ii) are **sub-parts** of 10(c), NOT separate questions\n",
      "- Recognition pattern: ^\\d+\\([a-z]\\)$ indicates sta\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Prompt Registry for V4 File-Based Workflow\"\"\"\n",
    "\n",
    "from typing import Dict, List, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class PromptRegistry:\n",
    "    \"\"\"ÈõÜ‰∏≠ÁÆ°ÁêÜ‰∏çÂêåÊ≠•È™§ÁöÑÂ§ßÊÆµ prompt ÁâáÊÆµÔºåÂèØÊåâ exam_type Á≠âÂèòÈáèÊ∏≤Êüì„ÄÇ\"\"\"\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        self._sections: Dict[str, List[str]] = {}\n",
    "        self._initialized = False\n",
    "    \n",
    "    def register(self, step: str, *sections: str) -> None:\n",
    "        \"\"\"Ê≥®ÂÜå‰∏Ä‰∏™Ê≠•È™§ÁöÑ prompt ÁâáÊÆµ\"\"\"\n",
    "        self._sections.setdefault(step, []).extend([s.strip() for s in sections if s])\n",
    "    \n",
    "    def build(self, step: str, **vars) -> str:\n",
    "        \"\"\"ÊûÑÂª∫ÊåáÂÆöÊ≠•È™§ÁöÑÂÆåÊï¥ promptÔºåÊîØÊåÅÂèòÈáèÊèíÂÄº\"\"\"\n",
    "        parts = self._sections.get(step, [])\n",
    "        if not parts:\n",
    "            raise ValueError(f\"No prompt registered for step: {step}\")\n",
    "        \n",
    "        # ÁÆÄÂçïÂèòÈáèÊèíÂÄºÔºàÊîØÊåÅ str.formatÔºâ\n",
    "        blob = \"\\n\\n\".join(\n",
    "            s.format(**vars) if \"{\" in s else s\n",
    "            for s in parts\n",
    "        )\n",
    "        return blob\n",
    "    \n",
    "    def register_all(self) -> None:\n",
    "        \"\"\"Ê≥®ÂÜåÊâÄÊúâÊ≠•È™§ÁöÑ promptsÔºà‰ªéÁé∞Êúâ agents ÊèêÂèñÔºâ\"\"\"\n",
    "        if self._initialized:\n",
    "            return\n",
    "        \n",
    "        self._register_classifier()\n",
    "        self._register_lister()\n",
    "        self._register_page_annotator()\n",
    "        self._register_question_latex()\n",
    "        self._register_answer_latex()\n",
    "        self._register_bbox_corrector()\n",
    "        self._register_labelling()\n",
    "        \n",
    "        self._initialized = True\n",
    "    \n",
    "    # ============= Step 0: Classifier =============\n",
    "    \n",
    "    def _register_classifier(self) -> None:\n",
    "        \"\"\"Ê≥®ÂÜåÂàÜÁ±ªÂô® prompt\"\"\"\n",
    "        self.register(\n",
    "            \"classify\",\n",
    "            \"\"\"Analyze the provided pages of this exam and determine its type.\"\"\",\n",
    "            \n",
    "            \"\"\"**Type1** (Separate Answer Booklet):\n",
    "- Explicitly states \"Use a SEPARATE writing booklet\" or similar\n",
    "- No blank lines or answer spaces under questions\n",
    "- Questions are densely packed\n",
    "- Example: \"10(a)\", \"10(b)\", \"10(c)\" are independent questions\"\"\",\n",
    "            \n",
    "            \"\"\"**Type2** (Answer on Paper):\n",
    "- Has blank lines or answer spaces under questions, including:\n",
    "  * Underscores (______)\n",
    "  * Dotted lines (..................)\n",
    "  * Multiple blank lines for writing answers\n",
    "- Clear answer spaces between questions\n",
    "- Questions have more spacing\n",
    "- Example: \"Question 21\" is one complete question with sub-parts (a), (b), (c)\"\"\",\n",
    "            \n",
    "            \"\"\"**Analysis Guidelines**:\n",
    "1. Look for explicit instructions about where to write answers\n",
    "2. Check for blank answer spaces or lines\n",
    "3. Observe question density and spacing\n",
    "4. Note the question numbering pattern\"\"\",\n",
    "            \n",
    "            \"\"\"Return JSON with:\n",
    "{{\n",
    "    \"exam_type\": \"type1\" or \"type2\",\n",
    "    \"reasoning\": \"Detailed explanation of classification decision\",\n",
    "    \"confidence\": 0.0-1.0 (optional)\n",
    "}}\n",
    "\n",
    "**Important**: Base your decision on multiple indicators, not just one feature.\"\"\"\n",
    "        )\n",
    "    \n",
    "    # ============= Step 1: Lister =============\n",
    "    \n",
    "    def _register_lister(self) -> None:\n",
    "        \"\"\"Ê≥®ÂÜåÂàóÈ¢òÂô® prompt\"\"\"\n",
    "        \n",
    "        # Type1 ËßÑÂàô\n",
    "        type1_rules = \"\"\"„ÄêType1 Rules„Äë(Separate Answer Booklet):\n",
    "- Question 10 is a **section title**, not an independent question\n",
    "- 10(a), 10(b), 10(c) are **independent questions** (minimum splitting unit)\n",
    "- 10(c)(i), 10(c)(ii) are **sub-parts** of 10(c), NOT separate questions\n",
    "- Recognition pattern: ^\\\\d+\\\\([a-z]\\\\)$ indicates start of independent question\n",
    "\n",
    "Example:\n",
    "  10          ‚Üê Section title, NOT a question\n",
    "  10(a)       ‚Üê Question 1: \"10(a)\"\n",
    "  10(b)       ‚Üê Question 2: \"10(b)\"\n",
    "  10(c)       ‚Üê Question 3: \"10(c)\"\n",
    "    (i)       ‚Üê Sub-part of 10(c), NOT separate\n",
    "    (ii)      ‚Üê Sub-part of 10(c), NOT separate\n",
    "  11(a)       ‚Üê Question 4: \"11(a)\" \"\"\"\n",
    "        \n",
    "        # Type2 ËßÑÂàô\n",
    "        type2_rules = \"\"\"„ÄêType2 Rules„Äë(Answer on Paper):\n",
    "- Each \"Question N\" (where N is a number) is **one complete question** (minimum splitting unit)\n",
    "- Sub-parts like (a), (b), (c) are NOT separate questions\n",
    "- Recognition pattern: ^Question \\\\d+$ indicates start of question\n",
    "- **IMPORTANT**: Include ALL questions from Question 1 onwards (including short/multiple-choice questions at the beginning)\n",
    "\n",
    "Example:\n",
    "  Question 1     ‚Üê Question 1: \"Question 1\" (may be a short/multiple-choice question)\n",
    "  Question 2     ‚Üê Question 2: \"Question 2\"\n",
    "  ...\n",
    "  Question 11    ‚Üê Question 11: \"Question 11\" (may have sub-parts below)\n",
    "    (a)          ‚Üê Sub-part of Question 11, NOT separate\n",
    "    (b)          ‚Üê Sub-part of Question 11, NOT separate\n",
    "  Question 12    ‚Üê Question 12: \"Question 12\"\n",
    "    (a)          ‚Üê Sub-part of Question 12, NOT separate\"\"\"\n",
    "        \n",
    "        self.register(\n",
    "            \"lister\",\n",
    "            \"\"\"You are a Question Lister Agent. Your task is to scan the entire paper PDF and create a **complete, accurate list** of all questions.\"\"\",\n",
    "            \n",
    "            \"\"\"=== Exam Type ===\n",
    "{exam_type}\"\"\",\n",
    "            \n",
    "            \"\"\"=== Question Splitting Rules ===\n",
    "{cutting_rules}\n",
    "{emphasis}\"\"\",\n",
    "            \n",
    "            \"\"\"=== Your Task ===\n",
    "1. Use the file_search tool to systematically scan the entire paper PDF\n",
    "2. Identify ALL questions in the document (from Question 1 to the last question)\n",
    "3. For each question, record:\n",
    "   - question_index: Sequential number starting from 1 (1, 2, 3, ...)\n",
    "   - question_label: **Exact label** as it appears in the paper (e.g., \"10(a)\", \"Question 1\", \"Question 21\")\"\"\",\n",
    "            \n",
    "            \"\"\"=== Search Strategy ===\n",
    "- **Start from Question 1** (or the first question in the document)\n",
    "- Search for ALL question patterns systematically (don't skip short/multiple-choice questions at the beginning)\n",
    "- Scan through the entire document from beginning to end\n",
    "- Verify you've reached the last question\n",
    "- Double-check the count and ensure Question 1 is included\"\"\",\n",
    "            \n",
    "            \"\"\"=== Critical Rules ===\n",
    "‚úÖ DO:\n",
    "- Follow the splitting rules **strictly**\n",
    "- **Start from Question 1** - don't skip early questions\n",
    "- Include ALL questions: short questions, multiple-choice questions, AND longer questions with sub-parts\n",
    "- Preserve exact question labels (including parentheses, capitalization)\n",
    "- Number questions sequentially (1, 2, 3, ...)\n",
    "- Include ALL questions, no matter how short\n",
    "\n",
    "‚ùå DON'T:\n",
    "- Skip the first few questions (e.g., Question 1-10)\n",
    "- Split sub-parts into separate questions\n",
    "- Guess or skip questions\n",
    "- Change the question labels\n",
    "- Include section titles as questions (for type1)\"\"\",\n",
    "            \n",
    "            \"\"\"=== Output Format ===\n",
    "**IMPORTANT: Return your response as a JSON object** with the following structure:\n",
    "{{\n",
    "    \"exam_type\": \"{exam_type}\",\n",
    "    \"total_questions\": <count>,\n",
    "    \"questions\": [\n",
    "        {{\"question_index\": 1, \"question_label\": \"...\"}},\n",
    "        {{\"question_index\": 2, \"question_label\": \"...\"}},\n",
    "        ...\n",
    "    ]\n",
    "}}\"\"\",\n",
    "            \n",
    "            \"\"\"=== Quality Check ===\n",
    "Before returning, verify:\n",
    "1. total_questions == len(questions)\n",
    "2. question_index are sequential (1, 2, 3, ...)\n",
    "3. No duplicate question_labels\n",
    "4. All question_labels follow the format rules\n",
    "\n",
    "Begin scanning now using the file_search tool. Be thorough and accurate!\"\"\"\n",
    "        )\n",
    "        \n",
    "        # ‰øùÂ≠òËßÑÂàôÊ®°Êùø‰ª•‰æøÂä®ÊÄÅÊ∏≤Êüì\n",
    "        self._sections[\"_lister_type1_rules\"] = [type1_rules]\n",
    "        self._sections[\"_lister_type2_rules\"] = [type2_rules]\n",
    "    \n",
    "    def _get_lister_emphasis(self, exam_type: str, emphasize: bool) -> str:\n",
    "        \"\"\"ÁîüÊàê lister ÁöÑÂº∫Ë∞ÉÊñáÊú¨ÔºàÈáçËØïÊó∂‰ΩøÁî®Ôºâ\"\"\"\n",
    "        if not emphasize:\n",
    "            return \"\"\n",
    "        \n",
    "        if exam_type == \"type1\":\n",
    "            return \"\"\"\n",
    "\n",
    "‚ö†Ô∏è **CRITICAL REMINDER for Type1**:\n",
    "- You MUST split questions to the (a), (b), (c) level\n",
    "- DO NOT list \"Question 10\" or \"Question 11\" as single questions\n",
    "- EVERY question label should contain (a), (b), (c), etc.\n",
    "- Example: If you see \"10(a)\", \"10(b)\", \"10(c)\", list them as THREE separate questions\n",
    "- Pattern to follow: \"10(a)\", \"10(b)\", \"10(c)\", \"11(a)\", \"11(b)\", etc.\n",
    "- This is a Type1 exam with SEPARATE answer booklet - questions are split into sub-parts!\"\"\"\n",
    "        else:  # type2\n",
    "            return \"\"\"\n",
    "\n",
    "‚ö†Ô∏è **CRITICAL REMINDER for Type2**:\n",
    "- You MUST NOT split (a), (b), (c) into separate questions\n",
    "- DO NOT list \"10(a)\", \"10(b)\" as separate questions\n",
    "- List ONLY \"Question N\" format (e.g., \"Question 1\", \"Question 2\")\n",
    "- If a question has sub-parts (a), (b), (c), they are ALL part of ONE question\n",
    "- Example: \"Question 11\" with (a), (b), (c) below = ONE question labeled \"Question 11\"\n",
    "- This is a Type2 exam - answers are written ON the paper, sub-parts are NOT separate!\"\"\"\n",
    "    \n",
    "    def build_lister_prompt(self, exam_type: str, emphasize: bool = False) -> str:\n",
    "        \"\"\"ÊûÑÂª∫ lister promptÔºàÁâπÊÆäÂ§ÑÁêÜ exam_type Âíå emphasisÔºâ\"\"\"\n",
    "        # Ëé∑ÂèñÂàáÈ¢òËßÑÂàô\n",
    "        if exam_type == \"type1\":\n",
    "            cutting_rules = self._sections.get(\"_lister_type1_rules\", [\"\"])[0]\n",
    "        else:\n",
    "            cutting_rules = self._sections.get(\"_lister_type2_rules\", [\"\"])[0]\n",
    "        \n",
    "        # Ëé∑ÂèñÂº∫Ë∞ÉÊñáÊú¨\n",
    "        emphasis = self._get_lister_emphasis(exam_type, emphasize)\n",
    "        \n",
    "        return self.build(\n",
    "            \"lister\",\n",
    "            exam_type=exam_type,\n",
    "            cutting_rules=cutting_rules,\n",
    "            emphasis=emphasis\n",
    "        )\n",
    "    \n",
    "    # ============= Step 1.5: Page Annotator =============\n",
    "    \n",
    "    def _register_page_annotator(self) -> None:\n",
    "        \"\"\"Ê≥®ÂÜåÈ°µÁ†ÅÊ†áÊ≥® prompt\"\"\"\n",
    "        \n",
    "        # Paper pages annotator\n",
    "        self.register(\n",
    "            \"annotate_paper\",\n",
    "            \"\"\"You are analyzing a paper PDF with page markers.\n",
    "\n",
    "The PDF has visible PAGE_INDEX_N markers (0-based) at the top-right of each page.\"\"\",\n",
    "            \n",
    "            \"\"\"Here are the questions in this paper:\n",
    "{questions_list}\"\"\",\n",
    "            \n",
    "            \"\"\"For EACH question, identify ALL pages where it appears (may span multiple pages).\"\"\",\n",
    "            \n",
    "            \"\"\"Return JSON:\n",
    "{{\n",
    "    \"annotations\": [\n",
    "        {{\"question_label\": \"10(a)\", \"paper_pages\": [5]}},\n",
    "        {{\"question_label\": \"10(b)\", \"paper_pages\": [6, 7]}},\n",
    "        ...\n",
    "    ]\n",
    "}}\"\"\",\n",
    "            \n",
    "            \"\"\"CRITICAL:\n",
    "- paper_pages is ALWAYS an array, even for single-page questions\n",
    "- Page indices are 0-based\n",
    "- Include ALL pages if question spans multiple pages\n",
    "- Return annotations for ALL {total_questions} questions\"\"\"\n",
    "        )\n",
    "        \n",
    "        # Solution pages annotator\n",
    "        self.register(\n",
    "            \"annotate_solution\",\n",
    "            \"\"\"You are analyzing a solution PDF with page markers.\n",
    "\n",
    "The PDF has visible PAGE_INDEX_N markers (0-based) at the top-right of each page.\"\"\",\n",
    "            \n",
    "            \"\"\"Here are the questions (you need to find their ANSWERS in this solution PDF):\n",
    "{questions_list}\"\"\",\n",
    "            \n",
    "            \"\"\"For EACH question, identify ALL pages where its ANSWER appears (may span multiple pages).\"\"\",\n",
    "            \n",
    "            \"\"\"Return JSON:\n",
    "{{\n",
    "    \"annotations\": [\n",
    "        {{\"question_label\": \"10(a)\", \"solution_pages\": [2]}},\n",
    "        {{\"question_label\": \"10(b)\", \"solution_pages\": [3, 4]}},\n",
    "        ...\n",
    "    ]\n",
    "}}\"\"\",\n",
    "            \n",
    "            \"\"\"CRITICAL:\n",
    "- solution_pages is ALWAYS an array, even for single-page answers\n",
    "- Page indices are 0-based\n",
    "- Include ALL pages if answer spans multiple pages\n",
    "- Return annotations for ALL {total_questions} questions\"\"\"\n",
    "        )\n",
    "    \n",
    "    # ============= Step 2: Question LaTeX Generator =============\n",
    "    \n",
    "    def _register_question_latex(self) -> None:\n",
    "        \"\"\"Ê≥®ÂÜåÈ¢òÁõÆ LaTeX ÁîüÊàê prompt\"\"\"\n",
    "        self.register(\n",
    "            \"question_latex\",\n",
    "            \"\"\"You are a professional LaTeX converter for exam questions.\"\"\",\n",
    "            \n",
    "            \"\"\"=== Your Task ===\n",
    "Convert question **{question_label}** from the PDF pages to clean, compilable LaTeX code.\"\"\",\n",
    "            \n",
    "            \"\"\"=== Question Location ===\n",
    "- Question Label: {question_label}\n",
    "- Paper Pages: [{pages_str}] (0-based page indexing)\n",
    "- **Note**: These page numbers are for reference. The actual question content may appear on nearby pages or span across adjacent pages.\"\"\",\n",
    "            \n",
    "            \"\"\"=== Conversion Guidelines ===\n",
    "\n",
    "1. **Read Question Content**:\n",
    "   - The question is expected around page(s) {pages_str}\n",
    "   - Check nearby pages if the question spans multiple pages or starts/ends on adjacent pages\n",
    "   - Read ALL content across these pages\n",
    "   - Include all sub-parts like (i), (ii), (iii) OR multiple choice options like A, B, C, D\n",
    "\n",
    "2. **Convert to LaTeX**:\n",
    "   - Use standard math environments: $...$ for inline, \\\\[...\\\\] or \\\\begin{{align*}}...\\\\end{{align*}} for display\n",
    "   - Keep structure clear and organized\n",
    "   - Use \\\\textbf{{}} for emphasis\n",
    "   - Convert all mathematical symbols accurately\n",
    "   - Preserve all formatting (fractions, powers, roots, etc.)\n",
    "   - **For multiple choice questions (A, B, C, D options), use \\\\begin{{enumerate}}[label=\\\\Alph*.] format**\n",
    "\n",
    "3. **Handle Images/Diagrams**:\n",
    "   - If you see an image, graph, or diagram, note its position\n",
    "   - Use placeholder: \\\\includegraphics[width=0.5\\\\textwidth]{{Figures/idPLACEHOLDER{question_index}_1.png}}\n",
    "   - For multiple images, use: Figures/idPLACEHOLDER{question_index}_1.png, Figures/idPLACEHOLDER{question_index}_2.png, etc.\n",
    "   - For each image, record:\n",
    "     * page_number: which page the image appears on (0-based)\n",
    "     * bbox: bounding box [x1, y1, x2, y2] (origin at top-left corner)\n",
    "     * description: brief description of the image\n",
    "\n",
    "4. **Formatting Rules**:\n",
    "   - **MUST start with: \\\\item** (do NOT include the question label)\n",
    "   - **For sub-parts (i), (ii), (iii), MUST use \\\\begin{{enumerate}}[label=(\\\\roman*)] and \\\\item**\n",
    "   - **For multiple choice questions (A, B, C, D), MUST use \\\\begin{{enumerate}}[label=\\\\Alph*.] and \\\\item**\n",
    "   - Keep consistent spacing\n",
    "   - Don't add extra section titles\n",
    "\n",
    "5. **Quality Check**:\n",
    "   - Verify all math brackets match: (), [], \\\\{{\\\\}}\n",
    "   - Check all LaTeX commands are spelled correctly\n",
    "   - Ensure completeness - don't miss any part\"\"\",\n",
    "            \n",
    "            \"\"\"=== Output Format ===\n",
    "Return ONLY valid JSON (no markdown, no code blocks):\n",
    "{{\n",
    "    \"question_label\": \"{question_label}\",\n",
    "    \"question_latex\": \"...complete LaTeX code...\",\n",
    "    \"question_images\": [\n",
    "        {{\n",
    "            \"page_number\": 5,\n",
    "            \"bbox\": [100.5, 200.3, 400.7, 500.2],\n",
    "            \"description\": \"Graph showing quadratic function\"\n",
    "        }}\n",
    "    ],\n",
    "    \"compilation_success\": true,\n",
    "    \"error_message\": null\n",
    "}}\"\"\",\n",
    "            \n",
    "            \"\"\"=== Examples ===\n",
    "\n",
    "Example 1 (simple):\n",
    "{{\n",
    "    \"question_label\": \"10(a)\",\n",
    "    \"question_latex\": \"\\\\\\\\item Solve the equation $x^2 + 3x - 4 = 0$.\",\n",
    "    \"question_images\": [],\n",
    "    \"compilation_success\": true,\n",
    "    \"error_message\": null\n",
    "}}\n",
    "\n",
    "Example 2 (with sub-parts):\n",
    "{{\n",
    "    \"question_label\": \"Question 11\",\n",
    "    \"question_latex\": \"\\\\\\\\item Consider the function $f(x) = x^2 - 4x + 3$.\\\\n\\\\\\\\begin{{enumerate}}[label=(\\\\\\\\roman*)]\\\\n\\\\\\\\item Find the vertex.\\\\n\\\\\\\\item Sketch the graph.\\\\n\\\\\\\\end{{enumerate}}\",\n",
    "    \"question_images\": [],\n",
    "    \"compilation_success\": true,\n",
    "    \"error_message\": null\n",
    "}}\n",
    "\n",
    "Example 3 (with images):\n",
    "{{\n",
    "    \"question_label\": \"Question 8\",\n",
    "    \"question_latex\": \"\\\\\\\\item The diagram shows a triangle ABC.\\\\n\\\\\\\\includegraphics[width=0.5\\\\\\\\textwidth]{{Figures/idPLACEHOLDER8_1.png}}\\\\n\\\\\\\\begin{{enumerate}}[label=(\\\\\\\\roman*)]\\\\n\\\\\\\\item Calculate the area.\\\\n\\\\\\\\item Find the perimeter.\\\\n\\\\\\\\end{{enumerate}}\",\n",
    "    \"question_images\": [\n",
    "        {{\n",
    "            \"page_number\": 3,\n",
    "            \"bbox\": [150.0, 250.0, 450.0, 500.0],\n",
    "            \"description\": \"Triangle ABC with sides labeled: AB = 5cm, BC = 4cm, AC = 3cm\"\n",
    "        }}\n",
    "    ],\n",
    "    \"compilation_success\": true,\n",
    "    \"error_message\": null\n",
    "}}\n",
    "\n",
    "Example 4 (multiple choice - MUST use this format):\n",
    "{{\n",
    "    \"question_label\": \"Question 3\",\n",
    "    \"question_latex\": \"\\\\\\\\item What is the derivative of $\\\\\\\\dfrac{{\\\\\\\\sin x}}{{e^x}}$?\\\\n\\\\\\\\begin{{enumerate}}[label=\\\\\\\\Alph*.]\\\\n\\\\\\\\item $\\\\\\\\dfrac{{\\\\\\\\sin x + \\\\\\\\cos x}}{{e^x}}$\\\\n\\\\\\\\item $\\\\\\\\dfrac{{\\\\\\\\sin x - \\\\\\\\cos x}}{{e^x}}$\\\\n\\\\\\\\item $-\\\\\\\\dfrac{{\\\\\\\\sin x + \\\\\\\\cos x}}{{e^x}}$\\\\n\\\\\\\\item $\\\\\\\\dfrac{{\\\\\\\\cos x - \\\\\\\\sin x}}{{e^x}}$\\\\n\\\\\\\\end{{enumerate}}\",\n",
    "    \"question_images\": [],\n",
    "    \"compilation_success\": true,\n",
    "    \"error_message\": null\n",
    "}}\n",
    "\n",
    "Now convert the question.\"\"\"\n",
    "        )\n",
    "    \n",
    "    # ============= Step 3: Answer LaTeX Generator =============\n",
    "    \n",
    "    def _register_answer_latex(self) -> None:\n",
    "        \"\"\"Ê≥®ÂÜåÁ≠îÊ°à LaTeX ÁîüÊàê prompt\"\"\"\n",
    "        self.register(\n",
    "            \"answer_latex\",\n",
    "            \"\"\"You are a professional LaTeX converter for exam answers/solutions.\"\"\",\n",
    "            \n",
    "            \"\"\"=== Your Task ===\n",
    "Convert the answer for question **{question_label}** from the solution PDF to clean, compilable LaTeX code.\"\"\",\n",
    "            \n",
    "            \"\"\"=== Answer Location ===\n",
    "- Question Label: {question_label}\n",
    "- Solution Pages: [{pages_str}] (0-based page indexing)\n",
    "- **Note**: These page numbers are for reference. The actual answer content may appear on nearby pages or span across adjacent pages.\"\"\",\n",
    "            \n",
    "            \"\"\"=== Conversion Guidelines ===\n",
    "\n",
    "1. **Read Solution Content**:\n",
    "   - The answer is expected around page(s) {pages_str}\n",
    "   - Check nearby pages if the solution spans multiple pages or starts/ends on adjacent pages\n",
    "   - Read ALL working and steps\n",
    "   - Include complete solution process\n",
    "\n",
    "2. **Convert to LaTeX**:\n",
    "   - Show all working steps clearly\n",
    "   - Use \\\\begin{{align*}}...\\\\end{{align*}} for multi-step calculations\n",
    "   - Use \\\\therefore, \\\\implies for logical connections\n",
    "   - Highlight final answer with \\\\boxed{{}} or \\\\textbf{{Answer:}}\n",
    "   - Include text explanations between steps\n",
    "\n",
    "3. **Extract Marks**:\n",
    "   - Look for marks indicators: \"[3 marks]\", \"(2m)\", \"3m\", etc.\n",
    "   - Extract the numerical value\n",
    "\n",
    "4. **Handle Images**:\n",
    "   - Note any solution diagrams or graphs\n",
    "   - Use placeholder: \\\\includegraphics[width=0.5\\\\textwidth]{{Figures/idPLACEHOLDER{question_index}_sol_1.png}}\n",
    "   - For multiple images, use: Figures/idPLACEHOLDER{question_index}_sol_1.png, Figures/idPLACEHOLDER{question_index}_sol_2.png, etc.\n",
    "   - For each image, record:\n",
    "     * page_number: which page the image appears on (0-based)\n",
    "     * bbox: bounding box [x1, y1, x2, y2] (origin at top-left corner)\n",
    "     * description: brief description of the image\n",
    "\n",
    "5. **Formatting Rules**:\n",
    "   - **MUST start with: \\\\item** (do NOT include the question label)\n",
    "   - **For answers with sub-parts (i), (ii), (iii), MUST use \\\\begin{{enumerate}}[label=(\\\\roman*)] and \\\\item for each sub-part**\n",
    "   - Clear step-by-step presentation\n",
    "   - Use \\\\text{{}} for English within math mode\n",
    "   - Show intermediate steps\n",
    "   - Emphasize final answer\"\"\",\n",
    "            \n",
    "            \"\"\"=== Output Format ===\n",
    "Return ONLY valid JSON:\n",
    "{{\n",
    "    \"question_label\": \"{question_label}\",\n",
    "    \"answer_latex\": \"...complete LaTeX solution...\",\n",
    "    \"answer_images\": [\n",
    "        {{\n",
    "            \"page_number\": 0,\n",
    "            \"bbox\": [100.5, 200.3, 400.7, 500.2],\n",
    "            \"description\": \"Solution diagram showing triangles\"\n",
    "        }}\n",
    "    ],\n",
    "    \"marks\": 3,\n",
    "    \"compilation_success\": true,\n",
    "    \"error_message\": null\n",
    "}}\"\"\",\n",
    "            \n",
    "            \"\"\"=== Examples ===\n",
    "\n",
    "Example 1 (without images):\n",
    "{{\n",
    "    \"question_label\": \"10(a)\",\n",
    "    \"answer_latex\": \"\\\\\\\\item \\\\\\\\begin{{align*}}\\\\nx^2 + 3x - 4 &= 0 \\\\\\\\\\\\\\\\\\\\n(x + 4)(x - 1) &= 0 \\\\\\\\\\\\\\\\\\\\nx &= -4 \\\\\\\\text{{ or }} x = 1\\\\n\\\\\\\\end{{align*}}\\\\n\\\\\\\\textbf{{Answer:}} $x = -4$ or $x = 1$\",\n",
    "    \"answer_images\": [],\n",
    "    \"marks\": 2,\n",
    "    \"compilation_success\": true,\n",
    "    \"error_message\": null\n",
    "}}\n",
    "\n",
    "Example 2 (with images):\n",
    "{{\n",
    "    \"question_label\": \"Question 5\",\n",
    "    \"answer_latex\": \"\\\\\\\\item \\\\\\\\includegraphics[width=0.5\\\\\\\\textwidth]{{Figures/idPLACEHOLDER5_sol_1.png}}\\\\n\\\\\\\\begin{{align*}}\\\\nArea &= \\\\\\\\frac{{1}}{{2}} \\\\\\\\times base \\\\\\\\times height \\\\\\\\\\\\\\\\\\\\n&= \\\\\\\\frac{{1}}{{2}} \\\\\\\\times 4 \\\\\\\\times 3 \\\\\\\\\\\\\\\\\\\\n&= 6 \\\\\\\\text{{ cm}}^2\\\\n\\\\\\\\end{{align*}}\",\n",
    "    \"answer_images\": [\n",
    "        {{\n",
    "            \"page_number\": 35,\n",
    "            \"bbox\": [50.0, 100.0, 300.0, 350.0],\n",
    "            \"description\": \"Diagram showing triangle with labeled sides\"\n",
    "        }}\n",
    "    ],\n",
    "    \"marks\": 3,\n",
    "    \"compilation_success\": true,\n",
    "    \"error_message\": null\n",
    "}}\n",
    "\n",
    "Now convert the answer.\"\"\"\n",
    "        )\n",
    "    \n",
    "    # ============= Step 4: Bbox Corrector =============\n",
    "    \n",
    "    def _register_bbox_corrector(self) -> None:\n",
    "        \"\"\"Ê≥®ÂÜå bbox ‰øÆÊ≠£ prompt\"\"\"\n",
    "        self.register(\n",
    "            \"bbox_correction\",\n",
    "            \"\"\"You are an expert at validating image crops from PDF documents.\"\"\",\n",
    "            \n",
    "            \"\"\"=== Your Task ===\n",
    "Verify if the cropped image correctly captures the {image_type} content for {question_label}.\"\"\",\n",
    "            \n",
    "            \"\"\"=== Current Crop Info ===\n",
    "- Question Label: {question_label}\n",
    "- Current BBox (PDF points): {current_bbox} (format: [x1, y1, x2, y2])\n",
    "- Current BBox (rendered pixels): [{bbox_rendered_str}]\n",
    "- Expected Content: {expected_description}\n",
    "- Image Type: {image_type}\"\"\",\n",
    "            \n",
    "            \"\"\"=== Dimension Information ===\n",
    "- PDF Page Size: {pdf_width:.1f} x {pdf_height:.1f} points (PDF coordinate system)\n",
    "- Rendered Page Size: {rendered_width} x {rendered_height} pixels\n",
    "- Cropped Image Size: {cropped_width} x {cropped_height} pixels\n",
    "- Scale Factor: {scale_x:.3f} (X), {scale_y:.3f} (Y) pixels per PDF point\"\"\",\n",
    "            \n",
    "            \"\"\"=== Important Context ===\n",
    "The expected description may include:\n",
    "- **For multiple choice questions**: The description may indicate which option the image belongs to (e.g., \"Image for option A\", \"Diagram for choice B\")\n",
    "- **For sub-parts**: The description may indicate which sub-part the image belongs to (e.g., \"Image for part (i)\", \"Diagram for part (ii)\")\n",
    "- **General descriptions**: The description may describe the image content (e.g., \"Graph showing quadratic function\", \"Triangle diagram\")\n",
    "\n",
    "When validating, pay special attention to:\n",
    "- If the description mentions an option (A, B, C, D), verify the crop includes ONLY that option's image\n",
    "- If the description mentions a sub-part (i, ii, iii), verify the crop includes ONLY that sub-part's image\n",
    "- Ensure the crop matches the specific context mentioned in the description\"\"\",\n",
    "            \n",
    "            \"\"\"=== Evaluation Criteria ===\n",
    "1. **Completeness**: Is all relevant content included?\n",
    "2. **Accuracy**: Is the content correctly identified and matches the expected description?\n",
    "3. **Context Match**: Does the crop match the specific context (option, sub-part, etc.) mentioned in the description?\n",
    "4. **Boundaries**: Are the boundaries appropriate (not too tight/loose)?\n",
    "5. **No Extra Content**: Is there minimal irrelevant content? For option-specific images, ensure no other options are included.\"\"\",\n",
    "            \n",
    "            \"\"\"=== Instructions ===\n",
    "1. Compare the cropped image with the rendered PDF page image\n",
    "2. Check if the crop matches the expected description, paying special attention to context (option, sub-part, etc.)\n",
    "3. Verify the crop includes only the relevant content mentioned in the description\n",
    "4. If incorrect, provide corrected coordinates in PDF points (not pixels)\n",
    "5. PDF coordinate system: origin at top-left, x increases right, y increases down\n",
    "6. Coordinate conversion: PDF points √ó scale_factor = rendered pixels\n",
    "7. The rendered page image shows the full PDF page, use it as reference to identify the correct crop area\"\"\",\n",
    "            \n",
    "            \"\"\"=== Common Issues to Check ===\n",
    "- Coordinates might be scaled incorrectly (e.g., pixel coordinates vs PDF points)\n",
    "- Crop might be too small or too large\n",
    "- Crop might be offset from the actual content\n",
    "- Content might span a larger area than the current bbox\"\"\",\n",
    "            \n",
    "            \"\"\"=== Output Format ===\n",
    "Return ONLY valid JSON:\n",
    "{{\n",
    "    \"is_correct\": true/false,\n",
    "    \"confidence\": 0.95,\n",
    "    \"issue_description\": \"Crop is too narrow, missing right side of diagram\" or null,\n",
    "    \"corrected_bbox\": [x1, y1, x2, y2] or null,\n",
    "    \"reasoning\": \"Detailed explanation of your decision...\"\n",
    "}}\n",
    "\n",
    "If crop is correct, set corrected_bbox to null.\n",
    "If crop needs correction, provide the corrected coordinates in PDF points.\n",
    "\n",
    "Now analyze the cropped image and the PDF page.\"\"\"\n",
    "        )\n",
    "    \n",
    "    # ============= Step 5: Labelling =============\n",
    "    \n",
    "    def _register_labelling(self) -> None:\n",
    "        \"\"\"Ê≥®ÂÜåÈ¢òÁõÆÊ†áÊ≥® prompt\"\"\"\n",
    "        self.register(\n",
    "            \"labelling\",\n",
    "            \"\"\"You are a Question Labelling Agent. Your task is to analyze a question and label it with accurate metadata.\"\"\",\n",
    "            \n",
    "            \"\"\"=== Question Information ===\n",
    "Question Index: {question_index}\n",
    "Question Label: {question_label}\"\"\",\n",
    "            \n",
    "            \"\"\"=== Question Content ===\n",
    "{question_latex}\n",
    "{answer_section}\"\"\",\n",
    "            \n",
    "            \"\"\"=== Your Task ===\n",
    "\n",
    "You need to label this question with the following metadata:\n",
    "\n",
    "1. **Topic and Subtopic** (MOST IMPORTANT):\n",
    "   - You MUST select the MOST ACCURATE subtopic from the provided list below\n",
    "   - You CANNOT create new topics or subtopics - you MUST choose from the list\n",
    "   - The subtopic_id is the MOST CRITICAL field - it must be accurate\n",
    "   - Provide a confidence score (0.0-1.0) for your subtopic selection\n",
    "   - If you are uncertain, explain why in the reasoning field\n",
    "\n",
    "2. **Question Type** (REQUIRED):\n",
    "   - You MUST choose EXACTLY ONE from: \"short answer\" OR \"multiple choice\"\n",
    "   - **Multiple Choice**: Has explicit options (A, B, C, D, etc.), usually with instructions like \"circle\", \"select\", \"choose\"\n",
    "   - **Short Answer**: Requires students to write their answer, may have blank lines, underscores, or answer spaces\n",
    "   - Look at the question structure and answer format to determine the type\n",
    "\n",
    "3. **Difficulty** (OPTIONAL):\n",
    "   - Assess the difficulty based on:\n",
    "     * Complexity of concepts involved\n",
    "     * Number of steps required to solve\n",
    "     * Level of mathematical reasoning needed\n",
    "   - Common values: \"Easy\", \"Medium\", \"Hard\", or specific difficulty levels\n",
    "   - If uncertain, you can leave it as null\n",
    "\n",
    "4. **Mark** (OPTIONAL):{mark_instruction}\"\"\",\n",
    "            \n",
    "            \"\"\"=== Available Topics and Subtopics ===\n",
    "\n",
    "You MUST select from this list (DO NOT create new ones):\n",
    "\n",
    "{subtopics_text}\n",
    "\n",
    "**CRITICAL RULES**:\n",
    "- You MUST select a subtopic_id from the list above\n",
    "- The subtopic_id is the MOST IMPORTANT field - accuracy is critical\n",
    "- If no subtopic matches perfectly, choose the CLOSEST match and explain in reasoning\n",
    "- Provide confidence score for your subtopic selection\"\"\",\n",
    "            \n",
    "            \"\"\"=== Output Format ===\n",
    "\n",
    "Return ONLY valid JSON (no markdown, no code blocks):\n",
    "{{\n",
    "    \"question_index\": {question_index},\n",
    "    \"question_label\": \"{question_label}\",\n",
    "    \"topic_id\": <integer>,\n",
    "    \"subtopic_id\": <integer>,\n",
    "    \"question_type\": \"short answer\" or \"multiple choice\",\n",
    "    \"difficulty\": \"<string>\" or null,\n",
    "    \"mark\": <integer> or null,\n",
    "    \"confidence\": <float between 0.0 and 1.0>,\n",
    "    \"reasoning\": \"<detailed explanation of your decisions, especially for subtopic selection>\"\n",
    "}}\"\"\",\n",
    "            \n",
    "            \"\"\"=== Examples ===\n",
    "\n",
    "Example 1 (Multiple Choice):\n",
    "{{\n",
    "    \"question_index\": 3,\n",
    "    \"question_label\": \"Question 3\",\n",
    "    \"topic_id\": 15,\n",
    "    \"subtopic_id\": 42,\n",
    "    \"question_type\": \"multiple choice\",\n",
    "    \"difficulty\": \"Medium\",\n",
    "    \"mark\": 2,\n",
    "    \"confidence\": 0.95,\n",
    "    \"reasoning\": \"This is a multiple choice question about derivatives. The subtopic 'Derivatives of Trigonometric Functions' (subtopic_id: 42) is the most accurate match. The question has 4 options (A, B, C, D) and asks to select the correct answer.\"\n",
    "}}\n",
    "\n",
    "Example 2 (Short Answer):\n",
    "{{\n",
    "    \"question_index\": 10,\n",
    "    \"question_label\": \"10(a)\",\n",
    "    \"topic_id\": 12,\n",
    "    \"subtopic_id\": 28,\n",
    "    \"question_type\": \"short answer\",\n",
    "    \"difficulty\": \"Hard\",\n",
    "    \"mark\": 5,\n",
    "    \"confidence\": 0.88,\n",
    "    \"reasoning\": \"This is a short answer question about quadratic equations. The subtopic 'Solving Quadratic Equations' (subtopic_id: 28) matches well. The question requires students to show their working and write the answer. The difficulty is high because it involves completing the square method.\"\n",
    "}}\n",
    "\n",
    "Now analyze the question and provide the labels.\"\"\"\n",
    "        )\n",
    "    \n",
    "    # ============= ËæÖÂä©ÊñπÊ≥ï =============\n",
    "    \n",
    "    def build_labelling_prompt(\n",
    "        self,\n",
    "        question_index: int,\n",
    "        question_label: str,\n",
    "        question_latex: str,\n",
    "        answer_latex: Optional[str],\n",
    "        subtopics_list: List[dict],\n",
    "        existing_mark: Optional[int] = None\n",
    "    ) -> str:\n",
    "        \"\"\"ÊûÑÂª∫ labelling promptÔºàÁâπÊÆäÂ§ÑÁêÜÂ≠ê‰∏ªÈ¢òÂàóË°®ÂíåÂàÜÊï∞Ôºâ\"\"\"\n",
    "        # ÊûÑÂª∫ subtopic ÈÄâÈ°πÂàóË°®\n",
    "        subtopics_text = \"\\n\".join([\n",
    "            f\"  {idx + 1}. Topic: {s.get('topic_name') or s.get('topicname', 'N/A')} \"\n",
    "            f\"(topic_id: {s.get('topicid') or s.get('topic_id', 'N/A')}) | \"\n",
    "            f\"Subtopic: {s.get('subtopic_name') or s.get('subtopicname', 'N/A')} \"\n",
    "            f\"(subtopic_id: {s.get('subtopicid') or s.get('subtopic_id', 'N/A')})\"\n",
    "            for idx, s in enumerate(subtopics_list)\n",
    "        ])\n",
    "        \n",
    "        # Mark ËØ¥Êòé\n",
    "        if existing_mark is not None:\n",
    "            mark_instruction = (\n",
    "                f\"\\n- **Mark**: The question already has a mark of {existing_mark}. \"\n",
    "                f\"Verify if this is correct based on the question content. If incorrect, extract the correct mark.\"\n",
    "            )\n",
    "        else:\n",
    "            mark_instruction = (\n",
    "                \"\\n- **Mark**: Extract the mark from the question \"\n",
    "                \"(look for notations like [5], [8 marks], etc.). If not found, leave as null.\"\n",
    "            )\n",
    "        \n",
    "        # Answer section\n",
    "        answer_section = \"\"\n",
    "        if answer_latex:\n",
    "            answer_section = f\"\"\"\n",
    "=== Answer Content ===\n",
    "{answer_latex}\n",
    "\n",
    "**Note**: The answer content can help you understand the question better and determine its difficulty.\n",
    "\"\"\"\n",
    "        \n",
    "        return self.build(\n",
    "            \"labelling\",\n",
    "            question_index=question_index,\n",
    "            question_label=question_label,\n",
    "            question_latex=question_latex,\n",
    "            answer_section=answer_section,\n",
    "            subtopics_text=subtopics_text,\n",
    "            mark_instruction=mark_instruction\n",
    "        )\n",
    "    \n",
    "    def get_all_steps(self) -> List[str]:\n",
    "        \"\"\"Ëé∑ÂèñÊâÄÊúâÂ∑≤Ê≥®ÂÜåÁöÑÊ≠•È™§ÂêçÁß∞\"\"\"\n",
    "        return [key for key in self._sections.keys() if not key.startswith(\"_\")]\n",
    "\n",
    "\n",
    "# ============= ÂÖ®Â±ÄÂçï‰æã =============\n",
    "\n",
    "PROMPTS = PromptRegistry()\n",
    "PROMPTS.register_all()\n",
    "\n",
    "\n",
    "# ============= ‰ΩøÁî®Á§∫‰æã =============\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Á§∫‰æã 1: Classifier\n",
    "    classifier_prompt = PROMPTS.build(\"classify\")\n",
    "    print(\"=== CLASSIFIER PROMPT ===\")\n",
    "    print(classifier_prompt[:500])\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Á§∫‰æã 2: Lister (Type1)\n",
    "    lister_prompt = PROMPTS.build_lister_prompt(exam_type=\"type1\", emphasize=False)\n",
    "    print(\"=== LISTER PROMPT (Type1) ===\")\n",
    "    print(lister_prompt[:500])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0460b670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)\n",
    "\n",
    "# agent = create_agent(\n",
    "#     model=llm,\n",
    "#     tools=[],\n",
    "#     system_prompt=\"You are an Australian high school teacher.\",\n",
    "# )\n",
    "\n",
    "# # === 3. ÊûÑÈÄ†Ê∂àÊÅØÂπ∂ÊâßË°å ===\n",
    "# question = HumanMessage(content=[\n",
    "#     {\"type\": \"text\", \"text\":\n",
    "#         \"You are an Australian high school teacher.\\n\"\n",
    "#         \"Please ONLY summarize the content of the third page of the solution PDF. Do NOT scan the whole PDF. \"\n",
    "#     },\n",
    "#     {\"type\": \"media\", \"mime_type\": \"application/pdf\", \"file_uri\": q_uri},\n",
    "#     {\"type\": \"media\", \"mime_type\": \"application/pdf\", \"file_uri\": s_uri},\n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58b7c935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import AgentMiddleware, ModelRequest, ModelResponse\n",
    "from typing import Callable, Awaitable\n",
    "\n",
    "class LongPromptMiddleware(AgentMiddleware):\n",
    "    \"\"\"\n",
    "    Ê†∏ÂøÉ‰∏≠Èó¥‰ª∂ÔºöÊ†πÊçÆ FlowContext Âä®ÊÄÅÁªÑË£Ö prompt„ÄÅË£ÅÂâ™ token„ÄÅÊéßÂà∂Â∑•ÂÖ∑\n",
    "    \"\"\"\n",
    "    \n",
    "    def wrap_model_call(\n",
    "        self,\n",
    "        request: ModelRequest,\n",
    "        handler: Callable[[ModelRequest], ModelResponse],\n",
    "    ) -> ModelResponse:\n",
    "        \"\"\"ÂêåÊ≠•ÁâàÊú¨\"\"\"\n",
    "        ctx: FlowContext = request.runtime.context\n",
    "        \n",
    "        # 1) Ê†πÊçÆÊ≠•È™§ÊûÑÂª∫Èïø prompt\n",
    "        if ctx.step == \"classify\":\n",
    "            long_system = PROMPTS.build(\"classify\")\n",
    "        elif ctx.step == \"lister\":\n",
    "            long_system = PROMPTS.build_lister_prompt(\n",
    "                exam_type=ctx.exam_type,\n",
    "                emphasize=(ctx.retry_count > 0)\n",
    "            )\n",
    "        elif ctx.step == \"question_latex\":\n",
    "            long_system = PROMPTS.build(\n",
    "                \"question_latex\",\n",
    "                question_label=ctx.current_question_label,\n",
    "                pages_str=\", \".join(map(str, ctx.paper_pages or [])),\n",
    "                question_index=ctx.current_question_index\n",
    "            )\n",
    "        elif ctx.step == \"answer_latex\":\n",
    "            long_system = PROMPTS.build(\n",
    "                \"answer_latex\",\n",
    "                question_label=ctx.current_question_label,\n",
    "                pages_str=\", \".join(map(str, ctx.solution_pages or [])),\n",
    "                question_index=ctx.current_question_index\n",
    "            )\n",
    "        else:\n",
    "            long_system = PROMPTS.build(ctx.step)\n",
    "        \n",
    "        # 2) Token Ë£ÅÂâ™\n",
    "        def rough_token_count(txt: str) -> int:\n",
    "            return max(1, len(txt) // 4)\n",
    "        \n",
    "        if rough_token_count(long_system) > ctx.token_budget:\n",
    "            long_system = long_system[:ctx.token_budget * 4]\n",
    "        \n",
    "        # 3) Ê≥®ÂÖ• system prompt\n",
    "        if request.system_prompt:\n",
    "            request.system_prompt = f\"{long_system}\\n\\n{request.system_prompt}\"\n",
    "        else:\n",
    "            request.system_prompt = long_system\n",
    "        \n",
    "        # 4) Â∑•ÂÖ∑ÁôΩÂêçÂçïÊéßÂà∂\n",
    "        step_config = ctx.get_step_config()\n",
    "        if not step_config.get(\"enable_tools\", True):\n",
    "            request.tools = []\n",
    "        \n",
    "        # 5) Ë∞ÉÁî®Ê®°Âûã\n",
    "        response = handler(request)\n",
    "        return response\n",
    "    \n",
    "    async def awrap_model_call(\n",
    "        self,\n",
    "        request: ModelRequest,\n",
    "        handler: Callable[[ModelRequest], Awaitable[ModelResponse]],\n",
    "    ) -> ModelResponse:\n",
    "        \"\"\"ÂºÇÊ≠•ÁâàÊú¨ ‚≠ê ËøôÊòØ‰øÆÂ§ç NotImplementedError ÁöÑÂÖ≥ÈîÆ\"\"\"\n",
    "        ctx: FlowContext = request.runtime.context\n",
    "        \n",
    "        # 1) Ê†πÊçÆÊ≠•È™§ÊûÑÂª∫Èïø prompt\n",
    "        if ctx.step == \"classify\":\n",
    "            long_system = PROMPTS.build(\"classify\")\n",
    "        elif ctx.step == \"lister\":\n",
    "            long_system = PROMPTS.build_lister_prompt(\n",
    "                exam_type=ctx.exam_type,\n",
    "                emphasize=(ctx.retry_count > 0)\n",
    "            )\n",
    "        elif ctx.step == \"question_latex\":\n",
    "            long_system = PROMPTS.build(\n",
    "                \"question_latex\",\n",
    "                question_label=ctx.current_question_label,\n",
    "                pages_str=\", \".join(map(str, ctx.paper_pages or [])),\n",
    "                question_index=ctx.current_question_index\n",
    "            )\n",
    "        elif ctx.step == \"answer_latex\":\n",
    "            long_system = PROMPTS.build(\n",
    "                \"answer_latex\",\n",
    "                question_label=ctx.current_question_label,\n",
    "                pages_str=\", \".join(map(str, ctx.solution_pages or [])),\n",
    "                question_index=ctx.current_question_index\n",
    "            )\n",
    "        else:\n",
    "            long_system = PROMPTS.build(ctx.step)\n",
    "        \n",
    "        # 2) Token Ë£ÅÂâ™\n",
    "        def rough_token_count(txt: str) -> int:\n",
    "            return max(1, len(txt) // 4)\n",
    "        \n",
    "        if rough_token_count(long_system) > ctx.token_budget:\n",
    "            long_system = long_system[:ctx.token_budget * 4]\n",
    "        \n",
    "        # 3) Ê≥®ÂÖ• system prompt\n",
    "        if request.system_prompt:\n",
    "            request.system_prompt = f\"{long_system}\\n\\n{request.system_prompt}\"\n",
    "        else:\n",
    "            request.system_prompt = long_system\n",
    "        \n",
    "        # 4) Â∑•ÂÖ∑ÁôΩÂêçÂçïÊéßÂà∂\n",
    "        step_config = ctx.get_step_config()\n",
    "        if not step_config.get(\"enable_tools\", True):\n",
    "            request.tools = []\n",
    "        \n",
    "        # 5) Ë∞ÉÁî®Ê®°ÂûãÔºàÂºÇÊ≠• awaitÔºâ\n",
    "        response = await handler(request)\n",
    "        return response\n",
    "\n",
    "\n",
    "class OutputValidationMiddleware(AgentMiddleware):\n",
    "    \"\"\"ËæìÂá∫Ê†°È™å‰∏≠Èó¥‰ª∂ÔºöÈ™åËØÅ JSON Ê†ºÂºè„ÄÅÂøÖÂ°´Â≠óÊÆµÁ≠â\"\"\"\n",
    "    \n",
    "    def wrap_model_call(\n",
    "        self,\n",
    "        request: ModelRequest,\n",
    "        handler: Callable[[ModelRequest], ModelResponse],\n",
    "    ) -> ModelResponse:\n",
    "        \"\"\"ÂêåÊ≠•ÁâàÊú¨\"\"\"\n",
    "        ctx: FlowContext = request.runtime.context\n",
    "        response = handler(request)\n",
    "        \n",
    "        # JSON Ê†°È™å - ÊîØÊåÅ markdown Ê†ºÂºè\n",
    "        if ctx.response_format == \"json_object\":\n",
    "            if response.result and len(response.result) > 0:\n",
    "                last_message = response.result[-1]\n",
    "                \n",
    "                if hasattr(last_message, 'content') and isinstance(last_message.content, str):\n",
    "                    try:\n",
    "                        import json\n",
    "                        import re\n",
    "                        \n",
    "                        content = last_message.content.strip()\n",
    "                        # ÊèêÂèñ markdown ‰ª£Á†ÅÂùó‰∏≠ÁöÑ JSON\n",
    "                        code_block_pattern = r'```(?:json)?\\s*\\n?(.*?)\\n?```'\n",
    "                        match = re.search(code_block_pattern, content, re.DOTALL)\n",
    "                        json_str = match.group(1).strip() if match else content\n",
    "                        \n",
    "                        json.loads(json_str)\n",
    "                        print(f\"‚úÖ JSON Ê†ºÂºèÈ™åËØÅÈÄöËøá (Ê≠•È™§: {ctx.step})\")\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"‚ö†Ô∏è JSON Ëß£ÊûêÂ§±Ë¥• (Ê≠•È™§: {ctx.step}): {e}\")\n",
    "                        print(f\"   ÂÜÖÂÆπ: {last_message.content[:200]}...\")\n",
    "                else:\n",
    "                    print(f\"‚ÑπÔ∏è ÊúÄÂêé‰∏ÄÊù°Ê∂àÊÅØ‰∏çÊòØÁ∫ØÊñáÊú¨ (Ê≠•È™§: {ctx.step})ÔºåË∑≥Ëøá JSON Ê†°È™å\")\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    async def awrap_model_call(\n",
    "        self,\n",
    "        request: ModelRequest,\n",
    "        handler: Callable[[ModelRequest], Awaitable[ModelResponse]],\n",
    "    ) -> ModelResponse:\n",
    "        \"\"\"ÂºÇÊ≠•ÁâàÊú¨ ‚≠ê\"\"\"\n",
    "        ctx: FlowContext = request.runtime.context\n",
    "        response = await handler(request)\n",
    "        \n",
    "        # JSON Ê†°È™å - ÊîØÊåÅ markdown Ê†ºÂºè\n",
    "        if ctx.response_format == \"json_object\":\n",
    "            if response.result and len(response.result) > 0:\n",
    "                last_message = response.result[-1]\n",
    "                \n",
    "                if hasattr(last_message, 'content') and isinstance(last_message.content, str):\n",
    "                    try:\n",
    "                        import json\n",
    "                        import re\n",
    "                        \n",
    "                        content = last_message.content.strip()\n",
    "                        # ÊèêÂèñ markdown ‰ª£Á†ÅÂùó‰∏≠ÁöÑ JSON\n",
    "                        code_block_pattern = r'```(?:json)?\\s*\\n?(.*?)\\n?```'\n",
    "                        match = re.search(code_block_pattern, content, re.DOTALL)\n",
    "                        json_str = match.group(1).strip() if match else content\n",
    "                        \n",
    "                        json.loads(json_str)\n",
    "                        print(f\"‚úÖ JSON Ê†ºÂºèÈ™åËØÅÈÄöËøá (Ê≠•È™§: {ctx.step})\")\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"‚ö†Ô∏è JSON Ëß£ÊûêÂ§±Ë¥• (Ê≠•È™§: {ctx.step}): {e}\")\n",
    "                        print(f\"   ÂÜÖÂÆπ: {last_message.content[:200]}...\")\n",
    "                else:\n",
    "                    print(f\"‚ÑπÔ∏è ÊúÄÂêé‰∏ÄÊù°Ê∂àÊÅØ‰∏çÊòØÁ∫ØÊñáÊú¨ (Ê≠•È™§: {ctx.step})ÔºåË∑≥Ëøá JSON Ê†°È™å\")\n",
    "        \n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d25ccb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Test 1: {'exam_type': 'type1'}\n",
      "‚úÖ Test 2: {'exam_type': 'type2'}\n",
      "‚úÖ Test 3: {'exam_type': 'type1'}\n",
      "‚úÖ Test 4: {'exam_type': 'type1'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def extract_json_from_markdown(content: str) -> dict:\n",
    "    \"\"\"\n",
    "    ‰ªéÊ®°ÂûãËøîÂõûÁöÑÂÜÖÂÆπ‰∏≠ÊèêÂèñ JSONÔºàÂ§ÑÁêÜ markdown ‰ª£Á†ÅÂùóÔºâ\n",
    "    \n",
    "    ÊîØÊåÅÊ†ºÂºèÔºö\n",
    "    1. ```json {...} ```\n",
    "    2. ``` {...} ```\n",
    "    3. Á∫Ø JSON {...}\n",
    "    \"\"\"\n",
    "    # ÂéªÈô§È¶ñÂ∞æÁ©∫ÁôΩ\n",
    "    content = content.strip()\n",
    "    \n",
    "    # Â∞ùËØïÊèêÂèñ markdown ‰ª£Á†ÅÂùó‰∏≠ÁöÑ JSON\n",
    "    # ÂåπÈÖç ```json ... ``` Êàñ ``` ... ```\n",
    "    code_block_pattern = r'```(?:json)?\\s*\\n?(.*?)\\n?```'\n",
    "    match = re.search(code_block_pattern, content, re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        # ÊèêÂèñ‰ª£Á†ÅÂùóÂÜÖÁöÑÂÜÖÂÆπ\n",
    "        json_str = match.group(1).strip()\n",
    "    else:\n",
    "        # Ê≤°Êúâ‰ª£Á†ÅÂùóÔºåÁõ¥Êé•‰ΩøÁî®ÂéüÂÜÖÂÆπ\n",
    "        json_str = content\n",
    "    \n",
    "    # Â∞ùËØïËß£Êûê JSON\n",
    "    try:\n",
    "        return json.loads(json_str)\n",
    "    except json.JSONDecodeError as e:\n",
    "        # Â¶ÇÊûúÂ§±Ë¥•ÔºåÂ∞ùËØïÊâæÂà∞Á¨¨‰∏Ä‰∏™ { ÂíåÊúÄÂêé‰∏Ä‰∏™ }\n",
    "        start = json_str.find('{')\n",
    "        end = json_str.rfind('}')\n",
    "        \n",
    "        if start != -1 and end != -1 and end > start:\n",
    "            json_str = json_str[start:end+1]\n",
    "            return json.loads(json_str)\n",
    "        else:\n",
    "            raise ValueError(f\"Êó†Ê≥ï‰ªéÂÜÖÂÆπ‰∏≠ÊèêÂèñ JSON: {content[:200]}...\") from e\n",
    "\n",
    "# ÊµãËØï\n",
    "test_cases = [\n",
    "    '```json\\n{\"exam_type\": \"type1\"}\\n```',\n",
    "    '```\\n{\"exam_type\": \"type2\"}\\n```',\n",
    "    '{\"exam_type\": \"type1\"}',\n",
    "    'Here is the result:\\n```json\\n{\"exam_type\": \"type1\"}\\n```\\nDone.'\n",
    "]\n",
    "\n",
    "for i, test in enumerate(test_cases):\n",
    "    try:\n",
    "        result = extract_json_from_markdown(test)\n",
    "        print(f\"‚úÖ Test {i+1}: {result}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Test {i+1}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a724fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "# 1. ÂàõÂª∫ LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-5\",  # ‚úÖ ‰øÆÂ§çÔºö‰ΩøÁî®Ê≠£Á°ÆÁöÑÊ®°ÂûãÂêç\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# 2. ÂÆö‰πâÂ∑•ÂÖ∑ÔºàÂ¶ÇÊûúÈúÄË¶Å file_searchÔºâ\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def file_search(query: str, file_id: str) -> str:\n",
    "    \"\"\"Search the PDF file by keyword/pattern\"\"\"\n",
    "    # ‚≠ê OpenAI ÁöÑ file search ÈúÄË¶Å‰ΩøÁî® Assistants API\n",
    "    # ËøôÈáåÁÆÄÂåñ‰∏∫Á§∫‰æã\n",
    "    return f\"Searched file {file_id} for: {query}\"\n",
    "\n",
    "TOOLS = [file_search]\n",
    "\n",
    "# 3. ÂàõÂª∫ AgentÔºàÂ∏¶‰∏≠Èó¥‰ª∂Ôºâ\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=TOOLS,\n",
    "    middleware=[\n",
    "        LongPromptMiddleware(),       # Âä®ÊÄÅ prompt Ê≥®ÂÖ•\n",
    "        OutputValidationMiddleware()  # JSON Ê†°È™å\n",
    "    ],\n",
    "    context_schema=FlowContext  # ÂÖÅËÆ∏‰º†ÂÖ• FlowContext\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "968fbf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Âú® notebook Êñ∞Â¢û cell\n",
    "from langchain.messages import HumanMessage\n",
    "\n",
    "async def run_classify_step(\n",
    "    paper_file_id: str,  \n",
    "    solution_file_id: str,  \n",
    "    exam_id: str\n",
    ") -> dict:\n",
    "    \"\"\"Step 0: ÂàÜÁ±ªËØïÂç∑Á±ªÂûã\"\"\"\n",
    "    \n",
    "    # 1. ÂàõÂª∫ context\n",
    "    context = FlowContext(\n",
    "        step=\"classify\",\n",
    "        exam_id=exam_id,\n",
    "        paper_file_id=paper_file_id, \n",
    "        solution_file_id=solution_file_id, \n",
    "        token_budget=8000,\n",
    "        response_format=\"json_object\"\n",
    "    )\n",
    "    \n",
    "    # 2. ÊûÑÂª∫Ê∂àÊÅØÔºà‚≠ê OpenAI Ê†ºÂºèÔºâ\n",
    "    message = HumanMessage(content=[\n",
    "        {\"type\": \"text\", \"text\": \"Analyze the exam type from these pages.\"},\n",
    "        {\"type\": \"file\", \"file_id\": paper_file_id} \n",
    "    ])\n",
    "    \n",
    "    # 3. Ë∞ÉÁî® agentÔºà‰º†ÂÖ• contextÔºâ\n",
    "    result = await agent.ainvoke(\n",
    "        {\"messages\": [message]},\n",
    "        context=context\n",
    "    )\n",
    "    \n",
    "    # 4. Ëß£ÊûêÁªìÊûúÔºà‰ΩøÁî® extract_json_from_markdown Â§ÑÁêÜ markdown ‰ª£Á†ÅÂùóÔºâ\n",
    "    content = result[\"messages\"][-1].content\n",
    "    output = extract_json_from_markdown(content)\n",
    "    \n",
    "    print(f\"‚úÖ ÂàÜÁ±ªÂÆåÊàê: {output['exam_type']}\")\n",
    "    print(f\"   ÁêÜÁî±: {output['reasoning']}\")\n",
    "    \n",
    "    return {\n",
    "        \"exam_type\": output[\"exam_type\"],\n",
    "        \"reasoning\": output[\"reasoning\"],\n",
    "        \"confidence\": output.get(\"confidence\")\n",
    "    }\n",
    "\n",
    "async def run_lister_step(\n",
    "    paper_file_id: str,\n",
    "    exam_type: str,\n",
    "    exam_id: str\n",
    ") -> dict:\n",
    "    \"\"\"Step 1: ÂàóÂá∫ÊâÄÊúâÈ¢òÁõÆ\"\"\"\n",
    "    \n",
    "    context = FlowContext(\n",
    "        step=\"lister\",\n",
    "        exam_id=exam_id,\n",
    "        exam_type=exam_type,\n",
    "        paper_file_id=paper_file_id,\n",
    "        token_budget=16000,\n",
    "        max_tokens=16000,\n",
    "        response_format=\"json_object\"\n",
    "    )\n",
    "    \n",
    "    message = HumanMessage(content=[\n",
    "        {\"type\": \"text\", \"text\": \"List all questions from the paper PDF.\"},\n",
    "        {\"type\": \"file\", \"file_id\": paper_file_id} \n",
    "    ])\n",
    "    \n",
    "    result = await agent.ainvoke(\n",
    "        {\"messages\": [message]},\n",
    "        context=context\n",
    "    )\n",
    "    \n",
    "    # Ëß£ÊûêÁªìÊûú\n",
    "    content = result[\"messages\"][-1].content\n",
    "    output = extract_json_from_markdown(content)\n",
    "    \n",
    "    print(f\"‚úÖ ÂàóÈ¢òÂÆåÊàê: {output['total_questions']} ÈÅìÈ¢ò\")\n",
    "    print(f\"   Ââç 3 È¢ò: {[q['question_label'] for q in output['questions'][:3]]}\")\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "async def run_question_latex_step(\n",
    "    paper_file_id: str,\n",
    "    question_index: int,\n",
    "    question_label: str,\n",
    "    paper_pages: list,\n",
    "    exam_id: str\n",
    ") -> dict:\n",
    "    \"\"\"Step 2: ÁîüÊàêÈ¢òÁõÆ LaTeX\"\"\"\n",
    "    \n",
    "    context = FlowContext(\n",
    "        step=\"question_latex\",\n",
    "        exam_id=exam_id,\n",
    "        current_question_index=question_index,\n",
    "        current_question_label=question_label,\n",
    "        paper_pages=paper_pages,\n",
    "        paper_file_id=paper_file_id,\n",
    "        token_budget=12000,\n",
    "        max_tokens=8000,\n",
    "        response_format=\"json_object\"\n",
    "    )\n",
    "    \n",
    "    message = HumanMessage(content=[\n",
    "        {\"type\": \"text\", \"text\": f\"Convert question {question_label} to LaTeX.\"},\n",
    "        {\"type\": \"file\", \"file_id\": paper_file_id} \n",
    "    ])\n",
    "    \n",
    "    result = await agent.ainvoke(\n",
    "        {\"messages\": [message]},\n",
    "        context=context\n",
    "    )\n",
    "    \n",
    "    # Ëß£ÊûêÁªìÊûú\n",
    "    content = result[\"messages\"][-1].content\n",
    "    output = extract_json_from_markdown(content)\n",
    "    \n",
    "    print(f\"‚úÖ È¢òÁõÆ LaTeX ÂÆåÊàê: {question_label}\")\n",
    "    print(f\"   LaTeX ÈïøÂ∫¶: {len(output['question_latex'])} Â≠óÁ¨¶\")\n",
    "    print(f\"   ÂõæÁâáÊï∞: {len(output.get('question_images', []))}\")\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc21463d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üöÄ ÂºÄÂßãÂ§ÑÁêÜËØïÂç∑: exam_test_001\n",
      "============================================================\n",
      "\n",
      "üìä Step 0: ÂàÜÁ±ªËØïÂç∑Á±ªÂûã...\n",
      "‚úÖ JSON Ê†ºÂºèÈ™åËØÅÈÄöËøá (Ê≠•È™§: classify)\n",
      "‚úÖ ÂàÜÁ±ªÂÆåÊàê: type1\n",
      "   ÁêÜÁî±: Multiple indicators point to a separate answer booklet format. (1) Explicit instructions: Section I (page 2/15) says 'Use the multiple-choice answer sheet for Questions 1‚Äì10.' Section II introduction (page 7/15) states 'Answer each question in the appropriate writing booklet. Extra writing booklets are available.' Each long-response question explicitly says 'Use a SEPARATE writing booklet.' (e.g., Question 11 on page 7/15, Question 12 on page 8/15, Question 13 on page 11/15, Question 14 on page 13/15). (2) No blank lines or answer spaces appear under the questions; content is densely packed across pages. (3) The provided sketch sheet for Q12(c) (page 15/15) is an insert to 'Place inside booklet for Q12,' reinforcing the separate booklet usage rather than answering on the paper itself. (4) Numbering and layout follow typical exam format with multi-part questions but without embedded answer areas.\n",
      "\n",
      "üìã Step 1: ÂàóÂá∫ÊâÄÊúâÈ¢òÁõÆ (Á±ªÂûã: type1)...\n",
      "‚úÖ JSON Ê†ºÂºèÈ™åËØÅÈÄöËøá (Ê≠•È™§: lister)\n",
      "‚úÖ ÂàóÈ¢òÂÆåÊàê: 28 ÈÅìÈ¢ò\n",
      "   Ââç 3 È¢ò: ['Question 1', 'Question 2', 'Question 3']\n",
      "\n",
      "üìù Step 2: ÁîüÊàêÈ¢òÁõÆ LaTeX (Â§ÑÁêÜÂâç 3 È¢ò)...\n",
      "‚úÖ JSON Ê†ºÂºèÈ™åËØÅÈÄöËøá (Ê≠•È™§: question_latex)\n",
      "‚úÖ È¢òÁõÆ LaTeX ÂÆåÊàê: Question 1\n",
      "   LaTeX ÈïøÂ∫¶: 428 Â≠óÁ¨¶\n",
      "   ÂõæÁâáÊï∞: 0\n",
      "‚úÖ JSON Ê†ºÂºèÈ™åËØÅÈÄöËøá (Ê≠•È™§: question_latex)\n",
      "‚úÖ È¢òÁõÆ LaTeX ÂÆåÊàê: Question 2\n",
      "   LaTeX ÈïøÂ∫¶: 286 Â≠óÁ¨¶\n",
      "   ÂõæÁâáÊï∞: 0\n",
      "‚úÖ JSON Ê†ºÂºèÈ™åËØÅÈÄöËøá (Ê≠•È™§: question_latex)\n",
      "‚úÖ È¢òÁõÆ LaTeX ÂÆåÊàê: Question 3\n",
      "   LaTeX ÈïøÂ∫¶: 207 Â≠óÁ¨¶\n",
      "   ÂõæÁâáÊï∞: 0\n",
      "‚úÖ JSON Ê†ºÂºèÈ™åËØÅÈÄöËøá (Ê≠•È™§: question_latex)\n",
      "‚úÖ È¢òÁõÆ LaTeX ÂÆåÊàê: Question 4\n",
      "   LaTeX ÈïøÂ∫¶: 348 Â≠óÁ¨¶\n",
      "   ÂõæÁâáÊï∞: 0\n"
     ]
    }
   ],
   "source": [
    "# Âú® notebook Êñ∞Â¢û cell\n",
    "async def run_complete_workflow(\n",
    "    paper_file_id: str,\n",
    "    solution_file_id: str,\n",
    "    exam_id: str = \"exam_001\"\n",
    "):\n",
    "    \"\"\"ÂÆåÊï¥ÊµÅÁ®ãÔºöÂàÜÁ±ª ‚Üí ÂàóÈ¢ò ‚Üí ÁîüÊàê LaTeX\"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(f\"üöÄ ÂºÄÂßãÂ§ÑÁêÜËØïÂç∑: {exam_id}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Step 0: ÂàÜÁ±ª\n",
    "    print(\"\\nüìä Step 0: ÂàÜÁ±ªËØïÂç∑Á±ªÂûã...\")\n",
    "    classify_result = await run_classify_step(paper_file_id, solution_file_id, exam_id)\n",
    "    exam_type = classify_result[\"exam_type\"]\n",
    "    \n",
    "    # Step 1: ÂàóÈ¢ò\n",
    "    print(f\"\\nüìã Step 1: ÂàóÂá∫ÊâÄÊúâÈ¢òÁõÆ (Á±ªÂûã: {exam_type})...\")\n",
    "    lister_result = await run_lister_step(paper_file_id, exam_type, exam_id)\n",
    "    questions = lister_result[\"questions\"]\n",
    "    \n",
    "    # Step 2: ÂØπÊØèÈÅìÈ¢òÁîüÊàê LaTeXÔºàÁ§∫‰æãÔºöÂè™Â§ÑÁêÜÂâç 3 È¢òÔºâ\n",
    "    print(f\"\\nüìù Step 2: ÁîüÊàêÈ¢òÁõÆ LaTeX (Â§ÑÁêÜÂâç 3 È¢ò)...\")\n",
    "    latex_results = []\n",
    "    for q in questions[:14]:\n",
    "        latex_result = await run_question_latex_step(\n",
    "            paper_file_id=paper_file_id,\n",
    "            question_index=q[\"question_index\"],\n",
    "            question_label=q[\"question_label\"],\n",
    "            paper_pages=[0],  # ÂÆûÈôÖÂ∫î‰ªé annotate Ê≠•È™§Ëé∑Âèñ\n",
    "            exam_id=exam_id\n",
    "        )\n",
    "        latex_results.append(latex_result)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚úÖ Â§ÑÁêÜÂÆåÊàêÔºÅ\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return {\n",
    "        \"exam_id\": exam_id,\n",
    "        \"exam_type\": exam_type,\n",
    "        \"total_questions\": lister_result[\"total_questions\"],\n",
    "        \"latex_results\": latex_results\n",
    "    }\n",
    "\n",
    "\n",
    "# ËøêË°åÂÆåÊï¥ÊµÅÁ®ã\n",
    "result = await run_complete_workflow(paper_file_id, solution_file_id, \"exam_test_001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d2b379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============= Êü•ÁúãÁîüÊàêÁöÑÂÜÖÂÆπ =============\n",
    "\n",
    "# 1. Êü•ÁúãÂàÜÁ±ªÁªìÊûú\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä ÂàÜÁ±ªÁªìÊûú\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ËØïÂç∑Á±ªÂûã: {result['exam_type']}\")\n",
    "print(f\"È¢òÁõÆÊÄªÊï∞: {result['total_questions']}\")\n",
    "\n",
    "# 2. Êü•ÁúãÁîüÊàêÁöÑ LaTeXÔºàÂâç 3 È¢òÔºâ\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìù ÁîüÊàêÁöÑ LaTeX ÂÜÖÂÆπ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, latex_result in enumerate(result['latex_results'], 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Question {i}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\n{latex_result['question_latex']}\\n\")\n",
    "    \n",
    "    if latex_result.get('question_images'):\n",
    "        print(f\"üì∑ ÂõæÁâáÊï∞: {len(latex_result['question_images'])}\")\n",
    "        for img in latex_result['question_images']:\n",
    "            print(f\"  - {img}\")\n",
    "\n",
    "# 3. ‰øùÂ≠òÁªìÊûúÂà∞Êñá‰ª∂\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "output_dir = \"./output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_file = f\"{output_dir}/exam_{result['exam_id']}_{timestamp}.json\"\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(result, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n‚úÖ ÁªìÊûúÂ∑≤‰øùÂ≠òÂà∞: {output_file}\")\n",
    "\n",
    "# 4. ÁîüÊàê LaTeX È¢ÑËßàÊñá‰ª∂\n",
    "latex_preview_file = f\"{output_dir}/exam_{result['exam_id']}_{timestamp}.tex\"\n",
    "\n",
    "with open(latex_preview_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"\\\\documentclass{article}\\n\")\n",
    "    f.write(\"\\\\usepackage{amsmath}\\n\")\n",
    "    f.write(\"\\\\usepackage{graphicx}\\n\")\n",
    "    f.write(\"\\\\begin{document}\\n\\n\")\n",
    "    f.write(f\"\\\\section*{{Exam: {result['exam_id']}}}\\n\")\n",
    "    f.write(f\"Type: {result['exam_type']}, Total Questions: {result['total_questions']}\\n\\n\")\n",
    "    \n",
    "    for i, latex_result in enumerate(result['latex_results'], 1):\n",
    "        f.write(f\"\\\\subsection*{{Question {i}}}\\n\")\n",
    "        f.write(latex_result['question_latex'])\n",
    "        f.write(\"\\n\\n\")\n",
    "    \n",
    "    f.write(\"\\\\end{document}\\n\")\n",
    "\n",
    "print(f\"‚úÖ LaTeX È¢ÑËßàÂ∑≤‰øùÂ≠òÂà∞: {latex_preview_file}\")\n",
    "print(f\"\\nüí° ÊèêÁ§∫: ÂèØ‰ª•Áî®‰ª•‰∏ãÂëΩ‰ª§ÁºñËØë LaTeX:\")\n",
    "print(f\"   cd {output_dir} && pdflatex {os.path.basename(latex_preview_file)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a8a8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============= Âø´ÈÄüÊü•ÁúãÂ∑•ÂÖ∑ =============\n",
    "\n",
    "def show_result_summary(result: dict):\n",
    "    \"\"\"ÊòæÁ§∫ÁªìÊûúÊëòË¶Å\"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(f\"üìã ËØïÂç∑ÊëòË¶Å: {result['exam_id']}\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Á±ªÂûã: {result['exam_type']}\")\n",
    "    print(f\"ÊÄªÈ¢òÊï∞: {result['total_questions']}\")\n",
    "    print(f\"Â∑≤ÁîüÊàê LaTeX: {len(result['latex_results'])} È¢ò\")\n",
    "    print()\n",
    "\n",
    "def show_question_latex(result: dict, question_num: int):\n",
    "    \"\"\"ÊòæÁ§∫ÊåáÂÆöÈ¢òÁõÆÁöÑ LaTeX\"\"\"\n",
    "    if question_num < 1 or question_num > len(result['latex_results']):\n",
    "        print(f\"‚ùå È¢òÂè∑Ë∂ÖÂá∫ËåÉÂõ¥ (1-{len(result['latex_results'])})\")\n",
    "        return\n",
    "    \n",
    "    latex_result = result['latex_results'][question_num - 1]\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(f\"üìù Question {question_num} LaTeX\")\n",
    "    print(\"=\"*70)\n",
    "    print(latex_result['question_latex'])\n",
    "    print()\n",
    "    \n",
    "    if latex_result.get('question_images'):\n",
    "        print(f\"üì∑ ÂõæÁâá: {len(latex_result['question_images'])} ‰∏™\")\n",
    "        for img in latex_result['question_images']:\n",
    "            print(f\"  - {img}\")\n",
    "    print()\n",
    "\n",
    "def compare_questions(result: dict):\n",
    "    \"\"\"ÂØπÊØîÊâÄÊúâÈ¢òÁõÆÁöÑ LaTeX ÈïøÂ∫¶\"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"üìä È¢òÁõÆÈïøÂ∫¶ÁªüËÆ°\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for i, latex_result in enumerate(result['latex_results'], 1):\n",
    "        latex_len = len(latex_result['question_latex'])\n",
    "        img_count = len(latex_result.get('question_images', []))\n",
    "        \n",
    "        print(f\"Q{i}: {latex_len:4d} Â≠óÁ¨¶, {img_count} ÂõæÁâá\")\n",
    "    print()\n",
    "\n",
    "# ‰ΩøÁî®Á§∫‰æã\n",
    "show_result_summary(result)\n",
    "compare_questions(result)\n",
    "\n",
    "# Êü•ÁúãÁ¨¨ 1 È¢òÁöÑËØ¶ÁªÜÂÜÖÂÆπ\n",
    "print(\"\\n\")\n",
    "show_question_latex(result, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2f7c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============= ÊèêÂèñÂíå‰øùÂ≠òÂõæÁâá =============\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def extract_images_from_pdf(pdf_path: str, result: dict, output_dir: str = \"./output/images\"):\n",
    "    \"\"\"\n",
    "    Ê†πÊçÆÁªìÊûú‰∏≠ÁöÑÂõæÁâá‰ø°ÊÅØÔºå‰ªé PDF ‰∏≠ÊèêÂèñÂõæÁâá\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: PDF Êñá‰ª∂Ë∑ØÂæÑ\n",
    "        result: workflow ÁîüÊàêÁöÑÁªìÊûú\n",
    "        output_dir: ÂõæÁâá‰øùÂ≠òÁõÆÂΩï\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # ÊâìÂºÄ PDF\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    extracted_images = []\n",
    "    total_images = 0\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"üì∑ ÊèêÂèñÂõæÁâá‰∏≠...\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for q_idx, latex_result in enumerate(result['latex_results'], 1):\n",
    "        if not latex_result.get('question_images'):\n",
    "            continue\n",
    "        \n",
    "        for img_idx, img_info in enumerate(latex_result['question_images']):\n",
    "            total_images += 1\n",
    "            \n",
    "            page_num = img_info['page_number']\n",
    "            bbox = img_info['bbox']  # [x0, y0, x1, y1]\n",
    "            \n",
    "            # ËØªÂèñÈ°µÈù¢\n",
    "            page = doc[page_num]\n",
    "            \n",
    "            # ÊèêÂèñÂå∫ÂüüÁöÑÂÉèÁ¥†ÂõæÔºàbbox Ê†ºÂºè: x0, y0, x1, y1Ôºâ\n",
    "            rect = fitz.Rect(bbox[0], bbox[1], bbox[2], bbox[3])\n",
    "            \n",
    "            # ËÆæÁΩÆÁº©ÊîæÊØî‰æãÔºàÊèêÈ´òÂàÜËæ®ÁéáÔºâ\n",
    "            mat = fitz.Matrix(2, 2)  # 2ÂÄçÊîæÂ§ß\n",
    "            pix = page.get_pixmap(matrix=mat, clip=rect)\n",
    "            \n",
    "            # ‰øùÂ≠òÂõæÁâá\n",
    "            img_filename = f\"q{q_idx}_img{img_idx+1}_p{page_num}.png\"\n",
    "            img_path = os.path.join(output_dir, img_filename)\n",
    "            pix.save(img_path)\n",
    "            \n",
    "            extracted_images.append({\n",
    "                'question': q_idx,\n",
    "                'image_index': img_idx + 1,\n",
    "                'page': page_num,\n",
    "                'filename': img_filename,\n",
    "                'path': img_path,\n",
    "                'bbox': bbox\n",
    "            })\n",
    "            \n",
    "            print(f\"‚úÖ Q{q_idx} ÂõæÁâá {img_idx+1}: {img_filename} (Page {page_num})\")\n",
    "    \n",
    "    doc.close()\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"‚úÖ ÊèêÂèñÂÆåÊàêÔºÅÂÖ± {total_images} Âº†ÂõæÁâá\")\n",
    "    print(f\"üìÅ ‰øùÂ≠ò‰ΩçÁΩÆ: {output_dir}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return extracted_images\n",
    "\n",
    "\n",
    "def update_latex_with_images(result: dict, images_info: list, output_dir: str = \"./output\"):\n",
    "    \"\"\"\n",
    "    Êõ¥Êñ∞ LaTeX Êñá‰ª∂ÔºåÂ∞Ü PLACEHOLDER ÊõøÊç¢‰∏∫ÂÆûÈôÖÁöÑÂõæÁâáË∑ØÂæÑ\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    latex_file = f\"{output_dir}/exam_{result['exam_id']}_with_images_{timestamp}.tex\"\n",
    "    \n",
    "    with open(latex_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"\\\\documentclass{article}\\n\")\n",
    "        f.write(\"\\\\usepackage{amsmath}\\n\")\n",
    "        f.write(\"\\\\usepackage{graphicx}\\n\")\n",
    "        f.write(\"\\\\usepackage{enumitem}\\n\")\n",
    "        f.write(\"\\\\begin{document}\\n\\n\")\n",
    "        f.write(f\"\\\\section*{{Exam: {result['exam_id']}}}\\n\")\n",
    "        f.write(f\"Type: {result['exam_type']}, Total Questions: {result['total_questions']}\\n\\n\")\n",
    "        \n",
    "        f.write(\"\\\\begin{enumerate}\\n\")\n",
    "        \n",
    "        for q_idx, latex_result in enumerate(result['latex_results'], 1):\n",
    "            latex_content = latex_result['question_latex']\n",
    "            \n",
    "            # ÊõøÊç¢ PLACEHOLDER ‰∏∫ÂÆûÈôÖÂõæÁâáË∑ØÂæÑ\n",
    "            if latex_result.get('question_images'):\n",
    "                for img_idx, img_info in enumerate(latex_result['question_images']):\n",
    "                    placeholder = f\"idPLACEHOLDER{q_idx}_{img_idx+1}\"\n",
    "                    actual_filename = f\"images/q{q_idx}_img{img_idx+1}_p{img_info['page_number']}.png\"\n",
    "                    latex_content = latex_content.replace(\n",
    "                        f\"Figures/{placeholder}.png\",\n",
    "                        actual_filename\n",
    "                    )\n",
    "            \n",
    "            f.write(latex_content)\n",
    "            f.write(\"\\n\\n\")\n",
    "        \n",
    "        f.write(\"\\\\end{enumerate}\\n\")\n",
    "        f.write(\"\\\\end{document}\\n\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Êõ¥Êñ∞ÁöÑ LaTeX Â∑≤‰øùÂ≠òÂà∞: {latex_file}\")\n",
    "    print(f\"\\nüí° ÁºñËØëÂëΩ‰ª§:\")\n",
    "    print(f\"   cd {output_dir} && pdflatex {os.path.basename(latex_file)}\")\n",
    "    \n",
    "    return latex_file\n",
    "\n",
    "\n",
    "# ‰ΩøÁî®Á§∫‰æã\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ÂºÄÂßãÊèêÂèñÂõæÁâá...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ÊèêÂèñÂõæÁâá\n",
    "images_info = extract_images_from_pdf(paper_pdf_path, result)\n",
    "\n",
    "# Êõ¥Êñ∞ LaTeX Êñá‰ª∂\n",
    "if images_info:\n",
    "    latex_file = update_latex_with_images(result, images_info)\n",
    "else:\n",
    "    print(\"\\n‚ÑπÔ∏è Ê≤°ÊúâÈúÄË¶ÅÊèêÂèñÁöÑÂõæÁâá\")\n",
    "\n",
    "# ÊòæÁ§∫ÂõæÁâá‰ø°ÊÅØÊëòË¶Å\n",
    "if images_info:\n",
    "    print(f\"\\nüìä ÂõæÁâáÊëòË¶Å:\")\n",
    "    for img in images_info:\n",
    "        print(f\"  Q{img['question']} - {img['filename']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b107c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============= Âú® Notebook ‰∏≠ÊòæÁ§∫ÂõæÁâá =============\n",
    "\n",
    "from IPython.display import display, Image as IPImage, HTML\n",
    "\n",
    "def show_extracted_images(images_info: list, max_width: int = 600):\n",
    "    \"\"\"Âú® notebook ‰∏≠ÊòæÁ§∫ÊèêÂèñÁöÑÂõæÁâá\"\"\"\n",
    "    if not images_info:\n",
    "        print(\"‚ÑπÔ∏è Ê≤°ÊúâÂõæÁâáÂèØÊòæÁ§∫\")\n",
    "        return\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(f\"üì∑ ÊòæÁ§∫ {len(images_info)} Âº†ÊèêÂèñÁöÑÂõæÁâá\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for img in images_info:\n",
    "        print(f\"\\n{'‚îÄ'*70}\")\n",
    "        print(f\"Question {img['question']} - ÂõæÁâá {img['image_index']} (Page {img['page']})\")\n",
    "        print(f\"Êñá‰ª∂: {img['filename']}\")\n",
    "        print(f\"{'‚îÄ'*70}\")\n",
    "        \n",
    "        # ÊòæÁ§∫ÂõæÁâá\n",
    "        display(IPImage(filename=img['path'], width=max_width))\n",
    "\n",
    "\n",
    "def show_question_with_images(result: dict, question_num: int, images_info: list):\n",
    "    \"\"\"ÊòæÁ§∫È¢òÁõÆÁöÑ LaTeX ÂíåÂØπÂ∫îÁöÑÂõæÁâá\"\"\"\n",
    "    if question_num < 1 or question_num > len(result['latex_results']):\n",
    "        print(f\"‚ùå È¢òÂè∑Ë∂ÖÂá∫ËåÉÂõ¥ (1-{len(result['latex_results'])})\")\n",
    "        return\n",
    "    \n",
    "    latex_result = result['latex_results'][question_num - 1]\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(f\"üìù Question {question_num}\")\n",
    "    print(\"=\"*70)\n",
    "    print(latex_result['question_latex'])\n",
    "    print()\n",
    "    \n",
    "    # ÊòæÁ§∫ËØ•È¢òÁöÑÂõæÁâá\n",
    "    question_images = [img for img in images_info if img['question'] == question_num]\n",
    "    \n",
    "    if question_images:\n",
    "        print(f\"üì∑ ËØ•È¢òÁöÑÂõæÁâá ({len(question_images)} Âº†):\")\n",
    "        for img in question_images:\n",
    "            print(f\"\\n{'‚îÄ'*70}\")\n",
    "            print(f\"ÂõæÁâá {img['image_index']} (Page {img['page']})\")\n",
    "            print(f\"{'‚îÄ'*70}\")\n",
    "            display(IPImage(filename=img['path'], width=500))\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è ËØ•È¢òÊ≤°ÊúâÂõæÁâá\")\n",
    "\n",
    "\n",
    "# ‰ΩøÁî®Á§∫‰æãÔºöÊòæÁ§∫ÊâÄÊúâÊèêÂèñÁöÑÂõæÁâá\n",
    "if images_info:\n",
    "    show_extracted_images(images_info)\n",
    "    \n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    # ÊòæÁ§∫Á¨¨‰∏ÄÈÅìÊúâÂõæÁâáÁöÑÈ¢òÁõÆ\n",
    "    first_q_with_img = images_info[0]['question'] if images_info else None\n",
    "    if first_q_with_img:\n",
    "        show_question_with_images(result, first_q_with_img, images_info)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
